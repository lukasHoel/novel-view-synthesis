{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4hmm4vcJti8k"
   },
   "source": [
    "# Basic Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PEG28Bp3aIAs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is on colab:  False\n"
     ]
    }
   ],
   "source": [
    "# Check device running the notebook automatically\n",
    "import sys\n",
    "is_on_colab = 'google.colab' in sys.modules\n",
    "print(\"Is on colab: \", is_on_colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yVHnBLJjvr-N"
   },
   "source": [
    "## Setup for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B1BOhxh7BEYm"
   },
   "outputs": [],
   "source": [
    "if is_on_colab:\n",
    "    # Google Colab setup\n",
    "\n",
    "    # Install pytorch3d\n",
    "    !pip install 'git+https://github.com/facebookresearch/pytorch3d.git'\n",
    "    \n",
    "    # Mount drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Retrieve repository and cd into root folder\n",
    "    from getpass import getpass\n",
    "    import urllib\n",
    "    import os\n",
    "    user = input('Github user name: ')\n",
    "    password = getpass('Github password: ')\n",
    "    password = urllib.parse.quote(password) # your password is converted into url format\n",
    "    branch = \"\" # \"-b \" + \"branch_name\"\n",
    "    cmd_string = 'git clone {0} https://{1}:{2}@github.com/lukasHoel/novel-view-synthesis.git'.format(branch, user, password)\n",
    "    os.system(cmd_string)\n",
    "    os.chdir(\"novel-view-synthesis\")\n",
    "\n",
    "    # Install PyTorch3D libraries (required for pointcloud computations.)\n",
    "    !pip install 'git+https://github.com/facebookresearch/pytorch3d.git'\n",
    "    !pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VF0QazUmv5lY"
   },
   "source": [
    "## Setup for Local Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VTsC8dapAyAD"
   },
   "outputs": [],
   "source": [
    "# ONLY NECESSARY FOR LOCAL EXECUTION (WORKS WITHOUT THIS CELL IN GOOGLE COLAB)\n",
    "# Setup that is necessary for jupyter notebook to find sibling-directories\n",
    "# see: https://stackoverflow.com/questions/34478398/import-local-function-from-a-module-housed-in-another-directory-with-relative-im\n",
    "\n",
    "\n",
    "if not is_on_colab:\n",
    "    \n",
    "    import os\n",
    "    import sys\n",
    "    module_path = os.path.abspath(os.path.join('..'))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gd7dyzCGwCZo"
   },
   "source": [
    "## General Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EGfclJp_AyA7"
   },
   "outputs": [],
   "source": [
    "# Imports for this notebook\n",
    "\n",
    "from models.nvs_model import NovelViewSynthesisModel\n",
    "from models.synthesis.synt_loss_metric import SynthesisLoss\n",
    "from util.nvs_solver import NVS_Solver\n",
    "from util.gan_wrapper_solver import GAN_Wrapper_Solver\n",
    "from data.nuim_dataloader import ICLNUIMDataset\n",
    "\n",
    "from torch.utils import data\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision.transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B7R9GHGlhsMQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is on GPU with CUDA: True\n",
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Check training on GPU?\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "print(\"Training is on GPU with CUDA: {}\".format(cuda))\n",
    "\n",
    "device = \"cuda:0\" if cuda else \"cpu\"\n",
    "\n",
    "print(\"Device: {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"Given a model return total number of parameters\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qKgCXiSPZgY1"
   },
   "source": [
    "# Model & Loss Init\n",
    "\n",
    "Instantiate and initialize NovelViewSynthesisModel and a selected flavor of SynthesisLoss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hzBJYgAlZgY2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss names: ('l1', 'content')\n",
      "Weight of each loss: ('1.0', '0.0')\n",
      "Model configuration: {'imageSize': 256, 'use_gt_depth': True, 'normalize_images': True, 'l1_loss': '1.0_l1', 'content_loss': '0.0_content', 'model': 'NovelViewSynthesisModel'}\n",
      "Architecture: NovelViewSynthesisModel(\n",
      "  (encoder): FeatureNet(\n",
      "    (res_blocks): Sequential(\n",
      "      (0): ResidualBlock(\n",
      "        (left_branch): Sequential(\n",
      "          (0): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): Identity()\n",
      "        )\n",
      "        (right_branch): Sequential(\n",
      "          (0): LinearNoiseLayer(\n",
      "            (gain): Linear(in_features=20, out_features=3, bias=False)\n",
      "            (bias): Linear(in_features=20, out_features=3, bias=False)\n",
      "            (bn): bn()\n",
      "          )\n",
      "          (1): ReLU()\n",
      "          (2): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LinearNoiseLayer(\n",
      "            (gain): Linear(in_features=20, out_features=8, bias=False)\n",
      "            (bias): Linear(in_features=20, out_features=8, bias=False)\n",
      "            (bn): bn()\n",
      "          )\n",
      "          (4): ReLU()\n",
      "          (5): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (6): Identity()\n",
      "        )\n",
      "      )\n",
      "      (1): ResidualBlock(\n",
      "        (left_branch): Sequential(\n",
      "          (0): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): Identity()\n",
      "        )\n",
      "        (right_branch): Sequential(\n",
      "          (0): LinearNoiseLayer(\n",
      "            (gain): Linear(in_features=20, out_features=8, bias=False)\n",
      "            (bias): Linear(in_features=20, out_features=8, bias=False)\n",
      "            (bn): bn()\n",
      "          )\n",
      "          (1): ReLU()\n",
      "          (2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LinearNoiseLayer(\n",
      "            (gain): Linear(in_features=20, out_features=16, bias=False)\n",
      "            (bias): Linear(in_features=20, out_features=16, bias=False)\n",
      "            (bn): bn()\n",
      "          )\n",
      "          (4): ReLU()\n",
      "          (5): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (6): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): ResidualBlock(\n",
      "        (left_branch): Sequential(\n",
      "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): Identity()\n",
      "        )\n",
      "        (right_branch): Sequential(\n",
      "          (0): LinearNoiseLayer(\n",
      "            (gain): Linear(in_features=20, out_features=16, bias=False)\n",
      "            (bias): Linear(in_features=20, out_features=16, bias=False)\n",
      "            (bn): bn()\n",
      "          )\n",
      "          (1): ReLU()\n",
      "          (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LinearNoiseLayer(\n",
      "            (gain): Linear(in_features=20, out_features=32, bias=False)\n",
      "            (bias): Linear(in_features=20, out_features=32, bias=False)\n",
      "            (bn): bn()\n",
      "          )\n",
      "          (4): ReLU()\n",
      "          (5): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (6): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pts_regressor): Unet(\n",
      "    (conv1): Conv2d(3, 4, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (conv2): Conv2d(4, 8, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (conv3): Conv2d(8, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (conv4): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (conv5): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (conv6): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (conv7): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (conv8): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    (dconv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (dconv2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (dconv3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (dconv4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (dconv5): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (dconv6): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (dconv7): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (dconv8): Conv2d(8, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (batch_norm): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (batch_norm2_0): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (batch_norm2_1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (batch_norm4_0): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (batch_norm4_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (batch_norm8_0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (batch_norm8_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (batch_norm8_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (batch_norm8_3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (batch_norm8_4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (batch_norm8_5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (batch_norm8_6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (batch_norm8_7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "    (relu): ReLU()\n",
      "    (tanh): Tanh()\n",
      "  )\n",
      "  (pts_transformer): PtsManipulator(\n",
      "    (splatter): RasterizePointsXYsBlending()\n",
      "  )\n",
      "  (projector): RefineNet(\n",
      "    (res_blocks): Sequential(\n",
      "      (0): ResidualBlock(\n",
      "        (left_branch): Sequential(\n",
      "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): Identity()\n",
      "        )\n",
      "        (right_branch): Sequential(\n",
      "          (0): LinearNoiseLayer(\n",
      "            (gain): Linear(in_features=20, out_features=32, bias=False)\n",
      "            (bias): Linear(in_features=20, out_features=32, bias=False)\n",
      "            (bn): bn()\n",
      "          )\n",
      "          (1): ReLU()\n",
      "          (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LinearNoiseLayer(\n",
      "            (gain): Linear(in_features=20, out_features=64, bias=False)\n",
      "            (bias): Linear(in_features=20, out_features=64, bias=False)\n",
      "            (bn): bn()\n",
      "          )\n",
      "          (4): ReLU()\n",
      "          (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (6): Identity()\n",
      "        )\n",
      "      )\n",
      "      (1): ResidualBlock(\n",
      "        (left_branch): Sequential(\n",
      "          (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "        )\n",
      "        (right_branch): Sequential(\n",
      "          (0): LinearNoiseLayer(\n",
      "            (gain): Linear(in_features=20, out_features=64, bias=False)\n",
      "            (bias): Linear(in_features=20, out_features=64, bias=False)\n",
      "            (bn): bn()\n",
      "          )\n",
      "          (1): ReLU()\n",
      "          (2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LinearNoiseLayer(\n",
      "            (gain): Linear(in_features=20, out_features=32, bias=False)\n",
      "            (bias): Linear(in_features=20, out_features=32, bias=False)\n",
      "            (bn): bn()\n",
      "          )\n",
      "          (4): ReLU()\n",
      "          (5): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (6): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "        )\n",
      "      )\n",
      "      (2): ResidualBlock(\n",
      "        (left_branch): Sequential(\n",
      "          (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
      "        )\n",
      "        (right_branch): Sequential(\n",
      "          (0): LinearNoiseLayer(\n",
      "            (gain): Linear(in_features=20, out_features=32, bias=False)\n",
      "            (bias): Linear(in_features=20, out_features=32, bias=False)\n",
      "            (bn): bn()\n",
      "          )\n",
      "          (1): ReLU()\n",
      "          (2): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LinearNoiseLayer(\n",
      "            (gain): Linear(in_features=20, out_features=16, bias=False)\n",
      "            (bias): Linear(in_features=20, out_features=16, bias=False)\n",
      "            (bn): bn()\n",
      "          )\n",
      "          (4): ReLU()\n",
      "          (5): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (6): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
      "        )\n",
      "      )\n",
      "      (3): ResidualBlock(\n",
      "        (left_branch): Sequential(\n",
      "          (0): Conv2d(16, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): Identity()\n",
      "        )\n",
      "        (right_branch): Sequential(\n",
      "          (0): LinearNoiseLayer(\n",
      "            (gain): Linear(in_features=20, out_features=16, bias=False)\n",
      "            (bias): Linear(in_features=20, out_features=16, bias=False)\n",
      "            (bn): bn()\n",
      "          )\n",
      "          (1): ReLU()\n",
      "          (2): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LinearNoiseLayer(\n",
      "            (gain): Linear(in_features=20, out_features=3, bias=False)\n",
      "            (bias): Linear(in_features=20, out_features=3, bias=False)\n",
      "            (bn): bn()\n",
      "          )\n",
      "          (4): ReLU()\n",
      "          (5): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (6): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (activate_out): Tanh()\n",
      "  )\n",
      ")\n",
      "Total number of paramaters: 282107\n"
     ]
    }
   ],
   "source": [
    "# TODO: Define more parameters in the dict according to availalbe ones in the model, as soon as they are needed.\n",
    "# Right now we just use the default parameters for the rest (see outcommented list or the .py file)\n",
    "    \n",
    "model_args={\n",
    "    'imageSize': 256,\n",
    "    'use_gt_depth': True,\n",
    "    'normalize_images': True,\n",
    "    'l1_loss': '1.0_l1',\n",
    "    'content_loss': '0.0_content', # synsin default: 10.0\n",
    "}\n",
    "\n",
    "# keep this loss object constant and modify usage of losses by e.g. setting one coefficient to 0\n",
    "nvs_loss = SynthesisLoss(losses=[\n",
    "    model_args['l1_loss'],\n",
    "    model_args['content_loss']\n",
    "])\n",
    "\n",
    "model = NovelViewSynthesisModel(imageSize=model_args['imageSize'],\n",
    "                                #max_z=0,\n",
    "                                #min_z=0,\n",
    "                                #enc_dims=[3, 8, 16, 32],\n",
    "                                #enc_blk_types=[\"id\", \"id\", \"id\"],\n",
    "                                #dec_dims=[32, 64, 32, 16, 3],\n",
    "                                #dec_blk_types=[\"id\", \"avg\", \"ups\", \"id\"],\n",
    "                                #points_per_pixel=8,\n",
    "                                #learn_feature=True,\n",
    "                                #radius=1.5,\n",
    "                                #rad_pow=2,\n",
    "                                #accumulation='alphacomposite',\n",
    "                                #accumulation_tau=1,\n",
    "                                #use_rgb_features=False,\n",
    "                                use_gt_depth=model_args['use_gt_depth'],\n",
    "                                #use_inverse_depth=False,\n",
    "                                normalize_images=model_args['normalize_images'])\n",
    "model_args[\"model\"] = type(model).__name__\n",
    "\n",
    "print(\"Model configuration: {}\".format(model_args))\n",
    "\n",
    "print(\"Architecture:\", model)\n",
    "print(\"Total number of paramaters:\", count_parameters(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QkO15Cr3t3pA"
   },
   "source": [
    "# Load Data\n",
    "Load ICL-NUIM dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TcKlv4vsAyBE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded following data: /home/lukas/Desktop/datasets/ICL-NUIM/prerendered_data/living_room_traj0_loop (samples: 60) with configuration: {'path': '/home/lukas/Desktop/datasets/ICL-NUIM/prerendered_data/living_room_traj0_loop', 'depth_to_image_plane': True, 'sampleOutput': True, 'RTrelativeToOutput': True, 'inverse_depth': False}\n"
     ]
    }
   ],
   "source": [
    "# Load dataset from drive or local\n",
    "\n",
    "if is_on_colab:\n",
    "    path = \"/content/drive/My Drive/Novel_View_Synthesis/ICL-NUIM/living_room_traj2_loop\"\n",
    "else:\n",
    "    path = \"/home/lukas/Desktop/datasets/ICL-NUIM/prerendered_data/living_room_traj0_loop\"\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToPILImage(),\n",
    "    torchvision.transforms.Resize((model_args['imageSize'], model_args['imageSize'])),\n",
    "    torchvision.transforms.ToTensor(), \n",
    "])\n",
    "    \n",
    "data_dict = {\n",
    "    \"path\": path,\n",
    "    \"depth_to_image_plane\": True,\n",
    "    \"sampleOutput\": True,\n",
    "    \"RTrelativeToOutput\": True,\n",
    "    \"inverse_depth\": False\n",
    "}\n",
    "    \n",
    "dataset = ICLNUIMDataset(path,\n",
    "                         transform=transform,\n",
    "                         depth_to_image_plane=data_dict[\"depth_to_image_plane\"],\n",
    "                         sampleOutput=data_dict[\"sampleOutput\"],\n",
    "                         RTrelativeToOutput=data_dict[\"RTrelativeToOutput\"],\n",
    "                         inverse_depth=data_dict[\"inverse_depth\"])\n",
    "\n",
    "print(\"Loaded following data: {} (samples: {}) with configuration: {}\".format(data_dict[\"path\"], len(dataset), data_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aJLyrjl2AyBK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parameters: {'batch_size': 1, 'validation_percentage': 0.2, 'shuffle_dataset': True, 'path': '/home/lukas/Desktop/datasets/ICL-NUIM/prerendered_data/living_room_traj0_loop', 'depth_to_image_plane': True, 'sampleOutput': True, 'RTrelativeToOutput': True, 'inverse_depth': False, 'train_len': 48, 'val_len': 12}\n"
     ]
    }
   ],
   "source": [
    "# Create Train and Val dataset with 80% train and 20% val.\n",
    "# from: https://stackoverflow.com/questions/50544730/how-do-i-split-a-custom-dataset-into-training-and-test-datasets\n",
    "\n",
    "dataset_args = {\n",
    "    \"batch_size\": 1,\n",
    "    \"validation_percentage\": 0.2,\n",
    "    \"shuffle_dataset\": True,\n",
    "    **data_dict\n",
    "}\n",
    "\n",
    "num_workers = 4\n",
    "random_seed = 42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(dataset_args[\"validation_percentage\"] * dataset_size))\n",
    "if dataset_args[\"shuffle_dataset\"]:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=dataset_args[\"batch_size\"], \n",
    "                                           sampler=train_sampler, num_workers=num_workers)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=dataset_args[\"batch_size\"],\n",
    "                                                sampler=valid_sampler, num_workers=num_workers)\n",
    "\n",
    "dataset_args[\"train_len\"] = len(train_loader)\n",
    "dataset_args[\"val_len\"] = len(validation_loader)\n",
    "\n",
    "print(\"Dataset parameters: {}\".format(dataset_args))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HeFz-j00u5LR"
   },
   "source": [
    "# Training Visualization\n",
    "\n",
    "Start Tensorboard for visualization of the upcoming training / validation / test steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c-6Mnrc-TPU9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-247a290237df8688\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-247a290237df8688\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start tensorboard. Might need to make sure, that the correct runs directory is chosen here.\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ../runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-zet9gPxvM2i"
   },
   "source": [
    "# Training\n",
    "\n",
    "Start training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This flag decides with solver gets used and where the logs will be logged into (into which directory)\n",
    "train_with_discriminator = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OTnq2RYJy4Dn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_dir: ../runs/Full_No_GAN/2020-May-02_20-40-47_705e0032-8ca4-11ea-bd96-29a6e8608218\n"
     ]
    }
   ],
   "source": [
    "# Create unique ID for this training process for saving to disk.\n",
    "\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "now = datetime.now() # current date and time\n",
    "id = str(uuid.uuid1())\n",
    "id_suffix = now.strftime(\"%Y-%b-%d_%H-%M-%S\") + \"_\" + id\n",
    "\n",
    "if train_with_discriminator:\n",
    "    log_dir_name = \"Full_GAN\"\n",
    "else:\n",
    "    log_dir_name = \"Full_No_GAN\"\n",
    "\n",
    "log_dir = \"../runs/\" + log_dir_name + \"/\" + id_suffix # Might need to make sure, that the correct runs directory is chosen here.\n",
    "print(\"log_dir:\", log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QY38vRjuAyBc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric names: PSNR SSIM\n",
      "Hyperparameters of this solver: {'loss_function': 'SynthesisLoss', 'optimizer': 'Adam', 'learning_rate': 0.0001, 'weight_decay': 0.0, 'imageSize': 256, 'use_gt_depth': True, 'normalize_images': True, 'l1_loss': '1.0_l1', 'content_loss': '0.0_content', 'model': 'NovelViewSynthesisModel', 'batch_size': 1, 'validation_percentage': 0.2, 'shuffle_dataset': True, 'path': '/home/lukas/Desktop/datasets/ICL-NUIM/prerendered_data/living_room_traj0_loop', 'depth_to_image_plane': True, 'sampleOutput': True, 'RTrelativeToOutput': True, 'inverse_depth': False, 'train_len': 48, 'val_len': 12}\n"
     ]
    }
   ],
   "source": [
    "# Configure solver\n",
    "extra_args = {\n",
    "    **model_args,\n",
    "    **dataset_args\n",
    "}\n",
    "\n",
    "if train_with_discriminator:\n",
    "    solver = GAN_Wrapper_Solver(optim_d=torch.optim.Adam,\n",
    "                                optim_d_args={\"lr\": 1e-2,\n",
    "                                              \"betas\": (0.9, 0.999),\n",
    "                                              \"eps\": 1e-8,\n",
    "                                              \"weight_decay\": 0.0},# is the l2 regularization parameter, see: https://pytorch.org/docs/stable/optim.html\n",
    "                                optim_g=torch.optim.Adam,\n",
    "                                optim_g_args={\"lr\": 1e-4,\n",
    "                                              \"betas\": (0.9, 0.999),\n",
    "                                              \"eps\": 1e-8,\n",
    "                                              \"weight_decay\": 0.0}, # is the l2 regularization parameter, see: https://pytorch.org/docs/stable/optim.html\n",
    "                                g_loss_func=nvs_loss,\n",
    "                                extra_args=extra_args,\n",
    "                                log_dir=log_dir,\n",
    "                                init_discriminator_weights=True)\n",
    "else:\n",
    "    solver = NVS_Solver(optim=torch.optim.Adam,\n",
    "                        optim_args={\"lr\": 1e-4,\n",
    "                                    \"betas\": (0.9, 0.999),\n",
    "                                    \"eps\": 1e-8,\n",
    "                                    \"weight_decay\": 0.0}, # is the l2 regularization parameter, see: https://pytorch.org/docs/stable/optim.html,\n",
    "                        loss_func=nvs_loss,\n",
    "                        extra_args=extra_args,\n",
    "                        tensorboard_writer=None, # let solver create a new instance\n",
    "                        log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1IhNe6ynzXox"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START TRAIN on device: cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0eec53cf4d4448288b6f9991d501df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=48.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukas/anaconda3/envs/nvs/lib/python3.8/site-packages/torch/nn/functional.py:2503: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\"Default upsampling behavior when mode={} is changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 1/48] TRAIN loss: 0.2918952405452728\n",
      "[Iteration 2/48] TRAIN loss: 0.34261560440063477\n",
      "[Iteration 3/48] TRAIN loss: 0.22200119495391846\n",
      "[Iteration 4/48] TRAIN loss: 0.33852991461753845\n",
      "[Iteration 5/48] TRAIN loss: 0.1971481442451477\n",
      "[Iteration 6/48] TRAIN loss: 0.3908124566078186\n",
      "[Iteration 7/48] TRAIN loss: 0.3311084508895874\n",
      "[Iteration 8/48] TRAIN loss: 0.17493268847465515\n",
      "[Iteration 9/48] TRAIN loss: 0.29720139503479004\n",
      "[Iteration 10/48] TRAIN loss: 0.1989189088344574\n",
      "[Iteration 11/48] TRAIN loss: 0.34136804938316345\n",
      "[Iteration 12/48] TRAIN loss: 0.15060940384864807\n",
      "[Iteration 13/48] TRAIN loss: 0.12441202998161316\n",
      "[Iteration 14/48] TRAIN loss: 0.1597576141357422\n",
      "[Iteration 15/48] TRAIN loss: 0.13874539732933044\n",
      "[Iteration 16/48] TRAIN loss: 0.2376292198896408\n",
      "[Iteration 17/48] TRAIN loss: 0.11821742355823517\n",
      "[Iteration 18/48] TRAIN loss: 0.10040841996669769\n",
      "[Iteration 19/48] TRAIN loss: 0.16471731662750244\n",
      "[Iteration 20/48] TRAIN loss: 0.14324864745140076\n",
      "[Iteration 21/48] TRAIN loss: 0.13764117658138275\n",
      "[Iteration 22/48] TRAIN loss: 0.17882660031318665\n",
      "[Iteration 23/48] TRAIN loss: 0.13764584064483643\n",
      "[Iteration 24/48] TRAIN loss: 0.15446552634239197\n",
      "[Iteration 25/48] TRAIN loss: 0.18238475918769836\n",
      "[Iteration 26/48] TRAIN loss: 0.1806095838546753\n",
      "[Iteration 27/48] TRAIN loss: 0.19479817152023315\n",
      "[Iteration 28/48] TRAIN loss: 0.16504137217998505\n",
      "[Iteration 29/48] TRAIN loss: 0.10639850795269012\n",
      "[Iteration 30/48] TRAIN loss: 0.21745042502880096\n",
      "[Iteration 31/48] TRAIN loss: 0.2375706136226654\n",
      "[Iteration 32/48] TRAIN loss: 0.13542109727859497\n",
      "[Iteration 33/48] TRAIN loss: 0.1786489486694336\n",
      "[Iteration 34/48] TRAIN loss: 0.14943917095661163\n",
      "[Iteration 35/48] TRAIN loss: 0.18803510069847107\n",
      "[Iteration 36/48] TRAIN loss: 0.16582059860229492\n",
      "[Iteration 37/48] TRAIN loss: 0.18457600474357605\n",
      "[Iteration 38/48] TRAIN loss: 0.1418445110321045\n",
      "[Iteration 39/48] TRAIN loss: 0.12669432163238525\n",
      "[Iteration 40/48] TRAIN loss: 0.30839109420776367\n",
      "[Iteration 41/48] TRAIN loss: 0.13507434725761414\n",
      "[Iteration 42/48] TRAIN loss: 0.08315624296665192\n",
      "[Iteration 43/48] TRAIN loss: 0.12963752448558807\n",
      "[Iteration 44/48] TRAIN loss: 0.16313622891902924\n",
      "[Iteration 45/48] TRAIN loss: 0.14241866767406464\n",
      "[Iteration 46/48] TRAIN loss: 0.19641153514385223\n",
      "[Iteration 47/48] TRAIN loss: 0.15926603972911835\n",
      "[Iteration 48/48] TRAIN loss: 0.2095559537410736\n",
      "\n",
      "[EPOCH 1/1] TRAIN mean acc/loss: 12.845630645751953/0.19072163105010986\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea0f495acc74a39b8a0750d275882dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 1/12] Val loss: 0.1816621869802475\n",
      "[Iteration 2/12] Val loss: 0.20887351036071777\n",
      "[Iteration 3/12] Val loss: 0.23364540934562683\n",
      "[Iteration 4/12] Val loss: 0.21651117503643036\n",
      "[Iteration 5/12] Val loss: 0.32738324999809265\n",
      "[Iteration 6/12] Val loss: 0.2950398921966553\n",
      "[Iteration 7/12] Val loss: 0.25499674677848816\n",
      "[Iteration 8/12] Val loss: 0.3325202465057373\n",
      "[Iteration 9/12] Val loss: 0.11476024240255356\n",
      "[Iteration 10/12] Val loss: 0.19382795691490173\n",
      "[Iteration 11/12] Val loss: 0.19090864062309265\n",
      "[Iteration 12/12] Val loss: 0.10695771872997284\n",
      "\n",
      "[EPOCH 1/1] VAL mean acc/loss: 12.033753395080566/0.2214239090681076\n",
      "FINISH.\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "\n",
    "num_epochs=1\n",
    "log_nth=1\n",
    "\n",
    "# TODO: Add parameters to extra_args dict?\n",
    "if train_with_discriminator:\n",
    "    steps = 1 # how many steps of training for discriminator/generator before switching to generator/discriminator\n",
    "    solver.train(model, train_loader, validation_loader, num_epochs=num_epochs, log_nth=log_nth, steps=steps)\n",
    "else:\n",
    "    solver.train(model, train_loader, validation_loader, num_epochs=num_epochs, log_nth=log_nth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tVWNikT4PvGj"
   },
   "outputs": [],
   "source": [
    "# To download tensorboard runs from Colab\n",
    "\n",
    "# TODO: Make sure that only new ones are copied --> for tensorboard runs on colab, do not use git repository as \"runs\" directory?\n",
    "# TODO: Instead of downloading, directly move it to the git repository that is currently checked out and push changes?\n",
    "if is_on_colab:\n",
    "  from google.colab import files\n",
    "  !zip -r /content/runs.zip /content/runs\n",
    "  files.download(\"/content/runs.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P2VDewrSvags"
   },
   "source": [
    "# Test\n",
    "\n",
    "Test with test dataset.\n",
    "Will load the data and start the training.\n",
    "\n",
    "Visualizations can be seen in Tensorboard above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d8S9-1x0zbHZ"
   },
   "outputs": [],
   "source": [
    "# Load test data\n",
    "# TODO: Find real test split, for now we load the SAME dataset as for train/val (just that this notebook is complete...)\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "test_path = path # CHANGE HERE TO REAL PATH TO TEST SET\n",
    "\n",
    "test_dataset = dataset = ICLNUIMDataset(test_path, transform=transform) # TODO also use rest of parameters...\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=dataset_args[\"batch_size\"], \n",
    "                                               shuffle=True,\n",
    "                                               num_workers=4)\n",
    "\n",
    "print(\"Length of test set: {}\".format(len(test_dataset)))\n",
    "print(\"Loaded test set: {}\".format(test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cl2sFO4Kynp6"
   },
   "outputs": [],
   "source": [
    "# Start testing\n",
    "\n",
    "solver.test(model, test_loader, test_prefix=\"DUMMY_TEST_WITH_NO_REAL_TEST_SET\", log_nth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pTLUJGpnBpud"
   },
   "source": [
    "# Save the model\n",
    "\n",
    "Save network with its weights to disk.\n",
    "\n",
    "See torch.save function: https://pytorch.org/docs/stable/notes/serialization.html#recommend-saving-models \n",
    "\n",
    "Load again with `the_model = TheModelClass(*args, **kwargs) the_model.load_state_dict(torch.load(PATH))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7_zjMVB7Bpue"
   },
   "outputs": [],
   "source": [
    "def save_model(modelname, model):\n",
    "    # Might need to make sure, that the correct saved_results directory is chosen here.\n",
    "    filepath = \"../saved_models/\" + modelname + \".pt\"\n",
    "    torch.save(model.state_dict(), filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2JfoL3IHBpuv"
   },
   "outputs": [],
   "source": [
    "nvs_modelname = \"nvs_\" + id_suffix\n",
    "save_model(nvs_modelname, model)\n",
    "\n",
    "# Also save the discriminator - currently this can only be accessed through the solver (change it!)\n",
    "gan_modelname = \"gan_\" + id_suffix\n",
    "save_model(gan_modelname, solver.netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BwbC3OFOEmLX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVS_Model loading:  <All keys matched successfully>\n",
      "Discriminator loading:  <All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "# LOAD MODEL AGAIN for verification purposes\n",
    "# Should print: <All keys matched successfully> per each model if it works\n",
    "\n",
    "nvs_filepath = \"../saved_models/\" + nvs_modelname + \".pt\"\n",
    "print(\"NVS_Model loading: \", model.load_state_dict(torch.load(nvs_filepath)))\n",
    "\n",
    "gan_filepath = \"../saved_models/\" + gan_modelname + \".pt\"\n",
    "print(\"Discriminator loading: \", solver.netD.load_state_dict(torch.load(gan_filepath)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "entire_network_notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
