{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "entire_network_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4hmm4vcJti8k"
      },
      "source": [
        "# Basic Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PEG28Bp3aIAs",
        "colab": {}
      },
      "source": [
        "# Check device running the notebook automatically\n",
        "import sys\n",
        "is_on_colab = 'google.colab' in sys.modules"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVHnBLJjvr-N",
        "colab_type": "text"
      },
      "source": [
        "## Setup for Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B1BOhxh7BEYm",
        "colab": {}
      },
      "source": [
        "if is_on_colab:\n",
        "    # Google Colab setup\n",
        "\n",
        "    # Mount drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Retrieve repository and cd into root folder\n",
        "    from getpass import getpass\n",
        "    import urllib\n",
        "    import os\n",
        "    user = input('Github user name: ')\n",
        "    password = getpass('Github password: ')\n",
        "    password = urllib.parse.quote(password) # your password is converted into url format\n",
        "    branch = \"\" # \"-b \" + \"branch_name\"\n",
        "    cmd_string = 'git clone {0} https://{1}:{2}@github.com/lukasHoel/novel-view-synthesis.git'.format(branch, user, password)\n",
        "    os.system(cmd_string)\n",
        "    os.chdir(\"novel-view-synthesis\")\n",
        "\n",
        "    # Install PyTorch3D libraries (required for pointcloud computations.)\n",
        "    !pip install 'git+https://github.com/facebookresearch/pytorch3d.git'\n",
        "    !pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VF0QazUmv5lY",
        "colab_type": "text"
      },
      "source": [
        "## Setup for Local Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VTsC8dapAyAD",
        "colab": {}
      },
      "source": [
        "# ONLY NECESSARY FOR LOCAL EXECUTION (WORKS WITHOUT THIS CELL IN GOOGLE COLAB)\n",
        "# Setup that is necessary for jupyter notebook to find sibling-directories\n",
        "# see: https://stackoverflow.com/questions/34478398/import-local-function-from-a-module-housed-in-another-directory-with-relative-im\n",
        "\n",
        "\n",
        "if not is_on_colab:\n",
        "    \n",
        "    import os\n",
        "    import sys\n",
        "    module_path = os.path.abspath(os.path.join('..'))\n",
        "    if module_path not in sys.path:\n",
        "        sys.path.append(module_path)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gd7dyzCGwCZo",
        "colab_type": "text"
      },
      "source": [
        "## General Settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EGfclJp_AyA7",
        "colab": {}
      },
      "source": [
        "# Imports for this notebook\n",
        "\n",
        "from util.nvs_solver import NVS_Solver\n",
        "from data.nuim_dataloader import ICLNUIMDataset\n",
        "from torch.utils import data\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision.transforms\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B7R9GHGlhsMQ",
        "colab": {}
      },
      "source": [
        "# Check training on GPU?\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "\n",
        "print(\"Training is on GPU with CUDA: {}\".format(cuda))\n",
        "\n",
        "device = \"cuda:0\" if cuda else \"cpu\"\n",
        "\n",
        "print(\"Device: {}\".format(device))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edjRs4EkuhKL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKgCXiSPZgY1",
        "colab_type": "text"
      },
      "source": [
        "# Novel View Synthesis Network Initialization\n",
        "\n",
        "Instantiate and initialize NovelViewSynthesisModel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzBJYgAlZgY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from models.nvs_model import NovelViewSynthesisModel\n",
        "        \n",
        "model_args={\n",
        "    # TODO\n",
        "}\n",
        "\n",
        "model = NovelViewSynthesisModel(W=5) # TODO: Parameters of NovelViewSynthesisModel, remove opt from PtsManipulator?\n",
        "model_args[\"model\"] = type(model).__name__\n",
        "\n",
        "print(\"Model configuration: {}\".format(model_args))\n",
        "\n",
        "print(\"Architecture:\", model)\n",
        "print(\"Total number of paramaters:\", count_parameters(model))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QkO15Cr3t3pA"
      },
      "source": [
        "# Load Data and Model\n",
        "\n",
        "Load ICL-NUIM dataset.\n",
        "\n",
        "Load the model for this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TcKlv4vsAyBE",
        "colab": {}
      },
      "source": [
        "# Load dataset from drive or local\n",
        "\n",
        "# TODO: Adjust paths\n",
        "if is_on_colab:\n",
        "    path = \"./data/sample\"\n",
        "else:\n",
        "    path = \"./data/sample\"\n",
        "\n",
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "])\n",
        "    \n",
        "data_dict = {\n",
        "    \"path\": path,\n",
        "}\n",
        "    \n",
        "dataset = ICLNUIMDataset(path, transform=transform)\n",
        "\n",
        "print(\"Loaded following data: {} (samples: {})\".format(data_dict[\"path\"], len(dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aJLyrjl2AyBK",
        "colab": {}
      },
      "source": [
        "# Create Train and Val dataset with 80% train and 20% val.\n",
        "# from: https://stackoverflow.com/questions/50544730/how-do-i-split-a-custom-dataset-into-training-and-test-datasets\n",
        "\n",
        "dataset_args = {\n",
        "    \"batch_size\": 32,\n",
        "    \"validation_percentage\": 0.2,\n",
        "    \"shuffle_dataset\": True,\n",
        "    \"depth_to_image_plane\": False,\n",
        "    **data_dict\n",
        "}\n",
        "\n",
        "num_workers = 4\n",
        "random_seed= 42\n",
        "\n",
        "# Creating data indices for training and validation splits:\n",
        "dataset_size = len(dataset)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(dataset_args[\"validation_percentage\"] * dataset_size))\n",
        "if dataset_args[\"shuffle_dataset\"]:\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "# NOTE: DataLoader normalizes images into range 0-1\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=dataset_args[\"batch_size\"], \n",
        "                                           sampler=train_sampler, num_workers=num_workers)\n",
        "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=dataset_args[\"batch_size\"],\n",
        "                                                sampler=valid_sampler, num_workers=num_workers)\n",
        "\n",
        "dataset_args[\"train_len\"] = len(train_loader)\n",
        "dataset_args[\"val_len\"] = len(validation_loader)\n",
        "\n",
        "print(\"Dataset parameters: {}\".format(dataset_args))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HeFz-j00u5LR"
      },
      "source": [
        "# Training Visualization\n",
        "\n",
        "Start Tensorboard for visualization of the upcoming training / validation / test steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c-6Mnrc-TPU9",
        "colab": {}
      },
      "source": [
        "# Start tensorboard. Might need to make sure, that the correct runs directory is chosen here.\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ../runs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR4f2jYAHq7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To clear previous tensorboard logs\n",
        "subdir = \"\"\n",
        "!rm -rf \"../runs/\" + subdir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-zet9gPxvM2i"
      },
      "source": [
        "# Training\n",
        "\n",
        "Start training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OTnq2RYJy4Dn",
        "colab": {}
      },
      "source": [
        "# Create unique ID for this training process for saving to disk.\n",
        "\n",
        "from datetime import datetime\n",
        "import uuid\n",
        "now = datetime.now() # current date and time\n",
        "id = str(uuid.uuid1())\n",
        "id_suffix = now.strftime(\"%Y-%b-%d_%H-%M-%S\") + \"_\" + id\n",
        "\n",
        "log_dir = \"../runs/FeatureNet/\" + id_suffix # Might need to make sure, that the correct runs directory is chosen here.\n",
        "print(\"log_dir:\", log_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QY38vRjuAyBc",
        "colab": {}
      },
      "source": [
        "# Configure solver\n",
        "extra_args = {\n",
        "    **model_args,\n",
        "    **dataset_args\n",
        "}\n",
        "\n",
        "solver = NVS_Solver(optim=torch.optim.Adam,\n",
        "                    optim_args={\"lr\": 0.0001,\n",
        "                                \"betas\": (0.9, 0.999),\n",
        "                                \"eps\": 1e-8,\n",
        "                                \"weight_decay\": 0.1}, # is the l2 regularization parameter, see: https://pytorch.org/docs/stable/optim.html\n",
        "                    extra_args=extra_args,\n",
        "                    log_dir=log_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1IhNe6ynzXox",
        "colab": {}
      },
      "source": [
        "# Start training\n",
        "\n",
        "solver.train(model, train_loader, validation_loader, num_epochs=20, log_nth=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVWNikT4PvGj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To download tensorboard runs from Colab\n",
        "if is_on_colab:\n",
        "  from google.colab import files\n",
        "  !zip -r /content/runs.zip /content/runs\n",
        "  files.download(\"/content/runs.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P2VDewrSvags"
      },
      "source": [
        "# Test\n",
        "\n",
        "Test with test dataset.\n",
        "Will load the data and start the training.\n",
        "\n",
        "Visualizations can be seen in Tensorboard above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d8S9-1x0zbHZ",
        "colab": {}
      },
      "source": [
        "# Load test data\n",
        "# TODO: Find real test split, for now we load the SAME dataset as for train/val (just that this notebook is complete...)\n",
        "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "\n",
        "test_path = path # CHANGE HERE TO REAL PATH TO TEST SET\n",
        "\n",
        "test_dataset = dataset = ICLNUIMDataset(test_path, transform=transform)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=dataset_args[\"batch_size\"], \n",
        "                                               shuffle=True,\n",
        "                                               num_workers=4)\n",
        "\n",
        "print(\"Length of test set: {}\".format(len(test_dataset)))\n",
        "print(\"Loaded test set: {}\".format(test_path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cl2sFO4Kynp6",
        "colab": {}
      },
      "source": [
        "# Start testing\n",
        "\n",
        "solver.test(model, test_loader, test_prefix=\"DUMMY_TEST_WITH_NO_REAL_TEST_SET\", log_nth=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pTLUJGpnBpud"
      },
      "source": [
        "# Save the model\n",
        "\n",
        "Save network with its weights to disk.\n",
        "\n",
        "See torch.save function: https://pytorch.org/docs/stable/notes/serialization.html#recommend-saving-models \n",
        "\n",
        "Load again with `the_model = TheModelClass(*args, **kwargs) the_model.load_state_dict(torch.load(PATH))`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7_zjMVB7Bpue",
        "colab": {}
      },
      "source": [
        "def save_model(modelname, model):\n",
        "    # Might need to make sure, that the correct saved_results directory is chosen here.\n",
        "    filepath = \"../saved_models/\" + modelname + \".pt\"\n",
        "    torch.save(model.state_dict(), filepath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2JfoL3IHBpuv",
        "colab": {}
      },
      "source": [
        "modelname = \"dummy_\" + id_suffix\n",
        "save_model(modelname, model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BwbC3OFOEmLX",
        "colab": {}
      },
      "source": [
        "# LOAD MODEL AGAIN for verification purposes\n",
        "# Should print: <All keys matched successfully>\n",
        "\n",
        "filepath = \"../saved_models/\" + modelname + \".pt\"\n",
        "model.load_state_dict(torch.load(filepath))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}