{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4hmm4vcJti8k"
   },
   "source": [
    "# Basic Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PEG28Bp3aIAs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is on colab:  False\n"
     ]
    }
   ],
   "source": [
    "# Check device running the notebook automatically\n",
    "import sys\n",
    "is_on_colab = 'google.colab' in sys.modules\n",
    "print(\"Is on colab: \", is_on_colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yVHnBLJjvr-N"
   },
   "source": [
    "## Setup for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B1BOhxh7BEYm"
   },
   "outputs": [],
   "source": [
    "if is_on_colab:\n",
    "    # Google Colab setup\n",
    "\n",
    "    # Mount drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Retrieve repository and cd into root folder\n",
    "    from getpass import getpass\n",
    "    import urllib\n",
    "    import os\n",
    "    user = input('Github user name: ')\n",
    "    password = getpass('Github password: ')\n",
    "    password = urllib.parse.quote(password) # your password is converted into url format\n",
    "    branch = \"\" # \"-b \" + \"branch_name\"\n",
    "    cmd_string = 'git clone {0} https://{1}:{2}@github.com/lukasHoel/novel-view-synthesis.git'.format(branch, user, password)\n",
    "    os.system(cmd_string)\n",
    "    os.chdir(\"novel-view-synthesis\")\n",
    "\n",
    "    # Install PyTorch3D libraries (required for pointcloud computations.)\n",
    "    !pip install 'git+https://github.com/facebookresearch/pytorch3d.git'\n",
    "    !pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VF0QazUmv5lY"
   },
   "source": [
    "## Setup for Local Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VTsC8dapAyAD"
   },
   "outputs": [],
   "source": [
    "# ONLY NECESSARY FOR LOCAL EXECUTION (WORKS WITHOUT THIS CELL IN GOOGLE COLAB)\n",
    "# Setup that is necessary for jupyter notebook to find sibling-directories\n",
    "# see: https://stackoverflow.com/questions/34478398/import-local-function-from-a-module-housed-in-another-directory-with-relative-im\n",
    "\n",
    "\n",
    "if not is_on_colab:\n",
    "    \n",
    "    import os\n",
    "    import sys\n",
    "    module_path = os.path.abspath(os.path.join('..'))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gd7dyzCGwCZo"
   },
   "source": [
    "## General Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EGfclJp_AyA7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Imports for this notebook\n",
    "\n",
    "from util.nvs_solver import NVS_Solver\n",
    "from util.gan_wrapper_solver import GAN_Wrapper_Solver\n",
    "from data.nuim_dataloader import ICLNUIMDataset\n",
    "from torch.utils import data\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision.transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B7R9GHGlhsMQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is on GPU with CUDA: True\n",
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Check training on GPU?\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "print(\"Training is on GPU with CUDA: {}\".format(cuda))\n",
    "\n",
    "device = \"cuda:0\" if cuda else \"cpu\"\n",
    "\n",
    "print(\"Device: {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"Given a model return total number of parameters\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qKgCXiSPZgY1"
   },
   "source": [
    "# Novel View Synthesis Network Initialization\n",
    "\n",
    "Instantiate and initialize NovelViewSynthesisModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hzBJYgAlZgY2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model configuration: {'imageSize': 256, 'use_gt_depth': True, 'normalize_images': True, 'model': 'NovelViewSynthesisModel'}\n",
      "Architecture: NovelViewSynthesisModel(\n",
      "  (encoder): FeatureNet(\n",
      "    (res_blocks): Sequential(\n",
      "      (0): ResidualBlock(\n",
      "        (left_branch): Sequential(\n",
      "          (0): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): Identity()\n",
      "        )\n",
      "        (right_branch): Sequential(\n",
      "          (0): LinearNoiseLayer(\n",
      "            (gain): Linear(in_features=20, out_features=3, bias=False)\n",
      "            (bias): Linear(in_features=20, out_features=3, bias=False)\n",
      "            (bn): bn()\n",
      "          )\n",
      "          (1): ReLU()\n",
      "          (2): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LinearNoiseLayer(\n",
      "            (gain): Linear(in_features=20, out_features=8, bias=False)\n",
      "            (bias): Linear(in_features=20, out_features=8, bias=False)\n",
      "            (bn): bn()\n",
      "          )\n",
      "          (4): ReLU()\n",
      "          (5): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (6): Identity()\n",
      "        )\n",
      "      )\n",
      "      (1): ResidualBlock(\n",
      "        (left_branch): Sequential(\n",
      "          (0): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): Identity()\n",
      "        )\n",
      "        (right_branch): Sequential(\n",
      "          (0): LinearNoiseLayer(\n",
      "            (gain): Linear(in_features=20, out_features=8, bias=False)\n",
      "            (bias): Linear(in_features=20, out_features=8, bias=False)\n",
      "            (bn): bn()\n",
      "          )\n",
      "          (1): ReLU()\n",
      "          (2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LinearNoiseLayer(\n",
      "            (gain): Linear(in_features=20, out_features=16, bias=False)\n",
      "            (bias): Linear(in_features=20, out_features=16, bias=False)\n",
      "            (bn): bn()\n",
      "          )\n",
      "          (4): ReLU()\n",
      "          (5): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (6): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): ResidualBlock(\n",
      "        (left_branch): Sequential(\n",
      "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): Identity()\n",
      "        )\n",
      "        (right_branch): Sequential(\n",
      "          (0): LinearNoiseLayer(\n",
      "            (gain): Linear(in_features=20, out_features=16, bias=False)\n",
      "            (bias): Linear(in_features=20, out_features=16, bias=False)\n",
      "            (bn): bn()\n",
      "          )\n",
      "          (1): ReLU()\n",
      "          (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LinearNoiseLayer(\n",
      "            (gain): Linear(in_features=20, out_features=32, bias=False)\n",
      "            (bias): Linear(in_features=20, out_features=32, bias=False)\n",
      "            (bn): bn()\n",
      "          )\n",
      "          (4): ReLU()\n",
      "          (5): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (6): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pts_regressor): Unet(\n",
      "    (conv1): Conv2d(3, 4, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (conv2): Conv2d(4, 8, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (conv3): Conv2d(8, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (conv4): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (conv5): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (conv6): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (conv7): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (conv8): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    (dconv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (dconv2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (dconv3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (dconv4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (dconv5): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (dconv6): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (dconv7): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (dconv8): Conv2d(8, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (batch_norm): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (batch_norm2_0): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (batch_norm2_1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (batch_norm4_0): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (batch_norm4_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (batch_norm8_0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (batch_norm8_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (batch_norm8_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (batch_norm8_3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (batch_norm8_4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (batch_norm8_5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (batch_norm8_6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (batch_norm8_7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "    (relu): ReLU()\n",
      "    (tanh): Tanh()\n",
      "  )\n",
      "  (pts_transformer): PtsManipulator(\n",
      "    (splatter): RasterizePointsXYsBlending()\n",
      "  )\n",
      "  (projector): RefineNet(\n",
      "    (res_blocks): Sequential(\n",
      "      (0): ResidualBlock(\n",
      "        (left_branch): Sequential(\n",
      "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): Identity()\n",
      "        )\n",
      "        (right_branch): Sequential(\n",
      "          (0): LinearNoiseLayer(\n",
      "            (gain): Linear(in_features=20, out_features=32, bias=False)\n",
      "            (bias): Linear(in_features=20, out_features=32, bias=False)\n",
      "            (bn): bn()\n",
      "          )\n",
      "          (1): ReLU()\n",
      "          (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LinearNoiseLayer(\n",
      "            (gain): Linear(in_features=20, out_features=64, bias=False)\n",
      "            (bias): Linear(in_features=20, out_features=64, bias=False)\n",
      "            (bn): bn()\n",
      "          )\n",
      "          (4): ReLU()\n",
      "          (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (6): Identity()\n",
      "        )\n",
      "      )\n",
      "      (1): ResidualBlock(\n",
      "        (left_branch): Sequential(\n",
      "          (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "        )\n",
      "        (right_branch): Sequential(\n",
      "          (0): LinearNoiseLayer(\n",
      "            (gain): Linear(in_features=20, out_features=64, bias=False)\n",
      "            (bias): Linear(in_features=20, out_features=64, bias=False)\n",
      "            (bn): bn()\n",
      "          )\n",
      "          (1): ReLU()\n",
      "          (2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LinearNoiseLayer(\n",
      "            (gain): Linear(in_features=20, out_features=32, bias=False)\n",
      "            (bias): Linear(in_features=20, out_features=32, bias=False)\n",
      "            (bn): bn()\n",
      "          )\n",
      "          (4): ReLU()\n",
      "          (5): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (6): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "        )\n",
      "      )\n",
      "      (2): ResidualBlock(\n",
      "        (left_branch): Sequential(\n",
      "          (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
      "        )\n",
      "        (right_branch): Sequential(\n",
      "          (0): LinearNoiseLayer(\n",
      "            (gain): Linear(in_features=20, out_features=32, bias=False)\n",
      "            (bias): Linear(in_features=20, out_features=32, bias=False)\n",
      "            (bn): bn()\n",
      "          )\n",
      "          (1): ReLU()\n",
      "          (2): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LinearNoiseLayer(\n",
      "            (gain): Linear(in_features=20, out_features=16, bias=False)\n",
      "            (bias): Linear(in_features=20, out_features=16, bias=False)\n",
      "            (bn): bn()\n",
      "          )\n",
      "          (4): ReLU()\n",
      "          (5): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (6): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
      "        )\n",
      "      )\n",
      "      (3): ResidualBlock(\n",
      "        (left_branch): Sequential(\n",
      "          (0): Conv2d(16, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): Identity()\n",
      "        )\n",
      "        (right_branch): Sequential(\n",
      "          (0): LinearNoiseLayer(\n",
      "            (gain): Linear(in_features=20, out_features=16, bias=False)\n",
      "            (bias): Linear(in_features=20, out_features=16, bias=False)\n",
      "            (bn): bn()\n",
      "          )\n",
      "          (1): ReLU()\n",
      "          (2): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LinearNoiseLayer(\n",
      "            (gain): Linear(in_features=20, out_features=3, bias=False)\n",
      "            (bias): Linear(in_features=20, out_features=3, bias=False)\n",
      "            (bn): bn()\n",
      "          )\n",
      "          (4): ReLU()\n",
      "          (5): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (6): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (activate_out): Tanh()\n",
      "  )\n",
      ")\n",
      "Total number of paramaters: 282107\n"
     ]
    }
   ],
   "source": [
    "from models.nvs_model import NovelViewSynthesisModel\n",
    "        \n",
    "# TODO: Define more parameters in the dict according to availalbe ones in the model, as soon as they are needed.\n",
    "# Right now we just use the default parameters for the rest (see outcommented list or the .py file)\n",
    "    \n",
    "model_args={\n",
    "    'imageSize': 256,\n",
    "    'use_gt_depth': True,\n",
    "    'normalize_images': True\n",
    "}\n",
    "\n",
    "model = NovelViewSynthesisModel(imageSize=model_args['imageSize'],\n",
    "                                #max_z=0,\n",
    "                                #min_z=0,\n",
    "                                #enc_dims=[3, 8, 16, 32],\n",
    "                                #enc_blk_types=[\"id\", \"id\", \"id\"],\n",
    "                                #dec_dims=[32, 64, 32, 16, 3],\n",
    "                                #dec_blk_types=[\"id\", \"avg\", \"ups\", \"id\"],\n",
    "                                #points_per_pixel=8,\n",
    "                                #learn_feature=True,\n",
    "                                #radius=1.5,\n",
    "                                #rad_pow=2,\n",
    "                                #accumulation='alphacomposite',\n",
    "                                #accumulation_tau=1,\n",
    "                                #use_rgb_features=False,\n",
    "                                use_gt_depth=model_args['use_gt_depth'],\n",
    "                                #use_inverse_depth=False,\n",
    "                                normalize_images=model_args['normalize_images'])\n",
    "model_args[\"model\"] = type(model).__name__\n",
    "\n",
    "print(\"Model configuration: {}\".format(model_args))\n",
    "\n",
    "print(\"Architecture:\", model)\n",
    "print(\"Total number of paramaters:\", count_parameters(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QkO15Cr3t3pA"
   },
   "source": [
    "# Load Data and Model\n",
    "\n",
    "Load ICL-NUIM dataset.\n",
    "\n",
    "Load the model for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TcKlv4vsAyBE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded following data: /home/lukas/Desktop/datasets/ICL-NUIM/prerendered_data/living_room_traj0_loop (samples: 60)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset from drive or local\n",
    "\n",
    "if is_on_colab:\n",
    "    path = \"/content/drive/My Drive/Novel_View_Synthesis/ICL-NUIM/living_room_traj2_loop\"\n",
    "else:\n",
    "    path = \"/home/lukas/Desktop/datasets/ICL-NUIM/prerendered_data/living_room_traj0_loop\"\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToPILImage(),\n",
    "    torchvision.transforms.Resize((model_args['imageSize'], model_args['imageSize'])),\n",
    "    torchvision.transforms.ToTensor(), \n",
    "])\n",
    "    \n",
    "data_dict = {\n",
    "    \"path\": path,\n",
    "    \"depth_to_image_plane\": True,\n",
    "    \"sampleOutput\": True,\n",
    "    \"RTrelativeToOutput\": True\n",
    "}\n",
    "    \n",
    "dataset = ICLNUIMDataset(path,\n",
    "                         transform=transform,\n",
    "                         depth_to_image_plane=data_dict[\"depth_to_image_plane\"],\n",
    "                         sampleOutput=data_dict[\"sampleOutput\"],\n",
    "                         RTrelativeToOutput=data_dict[\"RTrelativeToOutput\"])\n",
    "\n",
    "print(\"Loaded following data: {} (samples: {})\".format(data_dict[\"path\"], len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aJLyrjl2AyBK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parameters: {'batch_size': 1, 'validation_percentage': 0.2, 'shuffle_dataset': True, 'path': '/home/lukas/Desktop/datasets/ICL-NUIM/prerendered_data/living_room_traj0_loop', 'depth_to_image_plane': True, 'sampleOutput': True, 'RTrelativeToOutput': True, 'train_len': 48, 'val_len': 12}\n"
     ]
    }
   ],
   "source": [
    "# Create Train and Val dataset with 80% train and 20% val.\n",
    "# from: https://stackoverflow.com/questions/50544730/how-do-i-split-a-custom-dataset-into-training-and-test-datasets\n",
    "\n",
    "dataset_args = {\n",
    "    \"batch_size\": 1,\n",
    "    \"validation_percentage\": 0.2,\n",
    "    \"shuffle_dataset\": True,\n",
    "    **data_dict\n",
    "}\n",
    "\n",
    "num_workers = 4\n",
    "random_seed = 42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(dataset_args[\"validation_percentage\"] * dataset_size))\n",
    "if dataset_args[\"shuffle_dataset\"]:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=dataset_args[\"batch_size\"], \n",
    "                                           sampler=train_sampler, num_workers=num_workers)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=dataset_args[\"batch_size\"],\n",
    "                                                sampler=valid_sampler, num_workers=num_workers)\n",
    "\n",
    "dataset_args[\"train_len\"] = len(train_loader)\n",
    "dataset_args[\"val_len\"] = len(validation_loader)\n",
    "\n",
    "print(\"Dataset parameters: {}\".format(dataset_args))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HeFz-j00u5LR"
   },
   "source": [
    "# Training Visualization\n",
    "\n",
    "Start Tensorboard for visualization of the upcoming training / validation / test steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c-6Mnrc-TPU9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e119741db90b3c46\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e119741db90b3c46\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start tensorboard. Might need to make sure, that the correct runs directory is chosen here.\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ../runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-zet9gPxvM2i"
   },
   "source": [
    "# Training\n",
    "\n",
    "Start training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OTnq2RYJy4Dn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_dir: ../runs/Full_GAN/2020-May-02_17-17-03_f9fcc9f8-8c87-11ea-a8e1-b5bb5b4d1166\n"
     ]
    }
   ],
   "source": [
    "# Create unique ID for this training process for saving to disk.\n",
    "\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "now = datetime.now() # current date and time\n",
    "id = str(uuid.uuid1())\n",
    "id_suffix = now.strftime(\"%Y-%b-%d_%H-%M-%S\") + \"_\" + id\n",
    "\n",
    "log_dir = \"../runs/Full_GAN/\" + id_suffix # Might need to make sure, that the correct runs directory is chosen here.\n",
    "print(\"log_dir:\", log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QY38vRjuAyBc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss names: ('l1', 'content')\n",
      "Weight of each loss: ('1.0', '10.0')\n",
      "Metric names: PSNR SSIM\n",
      "Hyperparameters of this solver: {'loss_function': 'SynthesisLoss', 'optimizer': 'Adam', 'learning_rate': 0.0001, 'weight_decay': 0.0}\n",
      "Hyperparameters of this solver: {'discriminator': 'DiscriminatorLoss', 'discriminator_optim': 'Adam', 'discriminator_learning_rate': 0.01, 'generator_loss_function': 'SynthesisLoss', 'generator_optimizer': 'Adam', 'generator_learning_rate': 0.0001, 'generator_weight_decay': 0.0, 'imageSize': 256, 'use_gt_depth': True, 'normalize_images': True, 'model': 'NovelViewSynthesisModel', 'batch_size': 1, 'validation_percentage': 0.2, 'shuffle_dataset': True, 'path': '/home/lukas/Desktop/datasets/ICL-NUIM/prerendered_data/living_room_traj0_loop', 'depth_to_image_plane': True, 'sampleOutput': True, 'RTrelativeToOutput': True, 'train_len': 48, 'val_len': 12}\n"
     ]
    }
   ],
   "source": [
    "# Configure solver\n",
    "extra_args = {\n",
    "    **model_args,\n",
    "    **dataset_args\n",
    "}\n",
    "\n",
    "solver = GAN_Wrapper_Solver(optim_d=torch.optim.Adam,\n",
    "                            optim_d_args={\"lr\": 1e-2,\n",
    "                                          \"betas\": (0.9, 0.999),\n",
    "                                          \"eps\": 1e-8,\n",
    "                                          \"weight_decay\": 0.0},# is the l2 regularization parameter, see: https://pytorch.org/docs/stable/optim.html\n",
    "                            optim_g=torch.optim.Adam,\n",
    "                            optim_g_args={\"lr\": 1e-4,\n",
    "                                          \"betas\": (0.9, 0.999),\n",
    "                                          \"eps\": 1e-8,\n",
    "                                          \"weight_decay\": 0.0}, # is the l2 regularization parameter, see: https://pytorch.org/docs/stable/optim.html\n",
    "                            extra_args=extra_args,\n",
    "                            log_dir=log_dir,\n",
    "                            init_discriminator_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1IhNe6ynzXox"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START TRAIN on device: cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a0358db31b4395b28d17c5ade8eb3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=48.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 1/48] TRAIN loss: 7.538241386413574\n",
      "[Iteration 2/48] TRAIN loss: 7.869033336639404\n",
      "[Iteration 3/48] TRAIN loss: 8.330513954162598\n",
      "[Iteration 4/48] TRAIN loss: 8.49397087097168\n",
      "[Iteration 5/48] TRAIN loss: 8.666821479797363\n",
      "[Iteration 6/48] TRAIN loss: 8.862875938415527\n",
      "[Iteration 7/48] TRAIN loss: 7.075717449188232\n",
      "[Iteration 8/48] TRAIN loss: 7.625374794006348\n",
      "[Iteration 9/48] TRAIN loss: 8.058879852294922\n",
      "[Iteration 10/48] TRAIN loss: 7.006505966186523\n",
      "[Iteration 11/48] TRAIN loss: 7.666736125946045\n",
      "[Iteration 12/48] TRAIN loss: 7.244678497314453\n",
      "[Iteration 13/48] TRAIN loss: 6.825437545776367\n",
      "[Iteration 14/48] TRAIN loss: 6.811824798583984\n",
      "[Iteration 15/48] TRAIN loss: 8.37251091003418\n",
      "[Iteration 16/48] TRAIN loss: 8.35513973236084\n",
      "[Iteration 17/48] TRAIN loss: 7.765212059020996\n",
      "[Iteration 18/48] TRAIN loss: 7.505508899688721\n",
      "[Iteration 19/48] TRAIN loss: 9.040973663330078\n",
      "[Iteration 20/48] TRAIN loss: 7.010903835296631\n",
      "[Iteration 21/48] TRAIN loss: 8.298702239990234\n",
      "[Iteration 22/48] TRAIN loss: 7.681111812591553\n",
      "[Iteration 23/48] TRAIN loss: 9.3892183303833\n",
      "[Iteration 24/48] TRAIN loss: 7.3946967124938965\n",
      "[Iteration 25/48] TRAIN loss: 7.458888053894043\n",
      "[Iteration 26/48] TRAIN loss: 9.138664245605469\n",
      "[Iteration 27/48] TRAIN loss: 8.714079856872559\n",
      "[Iteration 28/48] TRAIN loss: 9.13421630859375\n",
      "[Iteration 29/48] TRAIN loss: 6.617283821105957\n",
      "[Iteration 30/48] TRAIN loss: 8.928300857543945\n",
      "[Iteration 31/48] TRAIN loss: 9.25589656829834\n",
      "[Iteration 32/48] TRAIN loss: 6.570083141326904\n",
      "[Iteration 33/48] TRAIN loss: 6.009950637817383\n",
      "[Iteration 34/48] TRAIN loss: 7.453381538391113\n",
      "[Iteration 35/48] TRAIN loss: 7.369903564453125\n",
      "[Iteration 36/48] TRAIN loss: 8.010655403137207\n",
      "[Iteration 37/48] TRAIN loss: 7.1908650398254395\n",
      "[Iteration 38/48] TRAIN loss: 10.026830673217773\n",
      "[Iteration 39/48] TRAIN loss: 8.624940872192383\n",
      "[Iteration 40/48] TRAIN loss: 6.618045330047607\n",
      "[Iteration 41/48] TRAIN loss: 8.936439514160156\n",
      "[Iteration 42/48] TRAIN loss: 8.24280071258545\n",
      "[Iteration 43/48] TRAIN loss: 7.872783184051514\n",
      "[Iteration 44/48] TRAIN loss: 8.873143196105957\n",
      "[Iteration 45/48] TRAIN loss: 7.089913845062256\n",
      "[Iteration 46/48] TRAIN loss: 7.10411262512207\n",
      "[Iteration 47/48] TRAIN loss: 5.697054386138916\n",
      "[Iteration 48/48] TRAIN loss: 7.220384120941162\n",
      "\n",
      "[EPOCH 1/1] TRAIN mean acc/loss: 4.03930139541626/7.855191707611084\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aa08a1bc6934c318f947991e44a21f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 1/12] Val loss: 6.059774875640869\n",
      "[Iteration 2/12] Val loss: 5.5447163581848145\n",
      "[Iteration 3/12] Val loss: 8.280570030212402\n",
      "[Iteration 4/12] Val loss: 6.681041717529297\n",
      "[Iteration 5/12] Val loss: 7.491840362548828\n",
      "[Iteration 6/12] Val loss: 7.240327835083008\n",
      "[Iteration 7/12] Val loss: 4.674778938293457\n",
      "[Iteration 8/12] Val loss: 7.050852298736572\n",
      "[Iteration 9/12] Val loss: 7.574456691741943\n",
      "[Iteration 10/12] Val loss: 4.849708080291748\n",
      "[Iteration 11/12] Val loss: 5.894941806793213\n",
      "[Iteration 12/12] Val loss: 7.013477325439453\n",
      "\n",
      "[EPOCH 1/1] VAL mean acc/loss: 3.7759361267089844/6.529707431793213\n",
      "FINISH.\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "\n",
    "# TODO: Add parameters to extra_args dict?\n",
    "\n",
    "solver.train(model, train_loader, validation_loader, num_epochs=1, log_nth=1, steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tVWNikT4PvGj"
   },
   "outputs": [],
   "source": [
    "# To download tensorboard runs from Colab\n",
    "\n",
    "# TODO: Make sure that only new ones are copied --> for tensorboard runs on colab, do not use git repository as \"runs\" directory?\n",
    "# TODO: Instead of downloading, directly move it to the git repository that is currently checked out and push changes?\n",
    "if is_on_colab:\n",
    "  from google.colab import files\n",
    "  !zip -r /content/runs.zip /content/runs\n",
    "  files.download(\"/content/runs.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P2VDewrSvags"
   },
   "source": [
    "# Test\n",
    "\n",
    "Test with test dataset.\n",
    "Will load the data and start the training.\n",
    "\n",
    "Visualizations can be seen in Tensorboard above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d8S9-1x0zbHZ"
   },
   "outputs": [],
   "source": [
    "# Load test data\n",
    "# TODO: Find real test split, for now we load the SAME dataset as for train/val (just that this notebook is complete...)\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "test_path = path # CHANGE HERE TO REAL PATH TO TEST SET\n",
    "\n",
    "test_dataset = dataset = ICLNUIMDataset(test_path, transform=transform) # TODO also use rest of parameters...\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=dataset_args[\"batch_size\"], \n",
    "                                               shuffle=True,\n",
    "                                               num_workers=4)\n",
    "\n",
    "print(\"Length of test set: {}\".format(len(test_dataset)))\n",
    "print(\"Loaded test set: {}\".format(test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cl2sFO4Kynp6"
   },
   "outputs": [],
   "source": [
    "# Start testing\n",
    "\n",
    "solver.test(model, test_loader, test_prefix=\"DUMMY_TEST_WITH_NO_REAL_TEST_SET\", log_nth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pTLUJGpnBpud"
   },
   "source": [
    "# Save the model\n",
    "\n",
    "Save network with its weights to disk.\n",
    "\n",
    "See torch.save function: https://pytorch.org/docs/stable/notes/serialization.html#recommend-saving-models \n",
    "\n",
    "Load again with `the_model = TheModelClass(*args, **kwargs) the_model.load_state_dict(torch.load(PATH))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7_zjMVB7Bpue"
   },
   "outputs": [],
   "source": [
    "def save_model(modelname, model):\n",
    "    # Might need to make sure, that the correct saved_results directory is chosen here.\n",
    "    filepath = \"../saved_models/\" + modelname + \".pt\"\n",
    "    torch.save(model.state_dict(), filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2JfoL3IHBpuv"
   },
   "outputs": [],
   "source": [
    "nvs_modelname = \"nvs_\" + id_suffix\n",
    "save_model(nvs_modelname, model)\n",
    "\n",
    "# Also save the discriminator - currently this can only be accessed through the solver (change it!)\n",
    "gan_modelname = \"gan_\" + id_suffix\n",
    "save_model(gan_modelname, solver.netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BwbC3OFOEmLX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVS_Model loading:  <All keys matched successfully>\n",
      "Discriminator loading:  <All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "# LOAD MODEL AGAIN for verification purposes\n",
    "# Should print: <All keys matched successfully> per each model if it works\n",
    "\n",
    "nvs_filepath = \"../saved_models/\" + nvs_modelname + \".pt\"\n",
    "print(\"NVS_Model loading: \", model.load_state_dict(torch.load(nvs_filepath)))\n",
    "\n",
    "gan_filepath = \"../saved_models/\" + gan_modelname + \".pt\"\n",
    "print(\"Discriminator loading: \", solver.netD.load_state_dict(torch.load(gan_filepath)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "entire_network_notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
