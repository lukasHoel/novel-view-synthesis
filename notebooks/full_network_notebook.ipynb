{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4hmm4vcJti8k"
   },
   "source": [
    "# Basic Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PEG28Bp3aIAs"
   },
   "outputs": [],
   "source": [
    "# Check device running the notebook automatically\n",
    "import sys\n",
    "is_on_colab = 'google.colab' in sys.modules\n",
    "print(\"Is on colab: \", is_on_colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yVHnBLJjvr-N"
   },
   "source": [
    "## Setup for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B1BOhxh7BEYm"
   },
   "outputs": [],
   "source": [
    "if is_on_colab:\n",
    "    # Google Colab setup\n",
    "    \n",
    "    # Mount drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Retrieve repository and cd into root folder\n",
    "    from getpass import getpass\n",
    "    import urllib\n",
    "    import os\n",
    "    user = input('Github user name: ')\n",
    "    password = getpass('Github password: ')\n",
    "    password = urllib.parse.quote(password) # your password is converted into url format\n",
    "    branch = \"\" # \"-b \" + \"branch_name\"\n",
    "    cmd_string = 'git clone {0} https://{1}:{2}@github.com/lukasHoel/novel-view-synthesis.git'.format(branch, user, password)\n",
    "    os.system(cmd_string)\n",
    "    os.chdir(\"novel-view-synthesis\")\n",
    "\n",
    "    # Install PyTorch3D libraries (required for pointcloud computations.)\n",
    "    !pip install 'git+https://github.com/facebookresearch/pytorch3d.git'\n",
    "    !pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VF0QazUmv5lY"
   },
   "source": [
    "## Setup for Local Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VTsC8dapAyAD"
   },
   "outputs": [],
   "source": [
    "# ONLY NECESSARY FOR LOCAL EXECUTION (WORKS WITHOUT THIS CELL IN GOOGLE COLAB)\n",
    "# Setup that is necessary for jupyter notebook to find sibling-directories\n",
    "# see: https://stackoverflow.com/questions/34478398/import-local-function-from-a-module-housed-in-another-directory-with-relative-im\n",
    "\n",
    "\n",
    "if not is_on_colab:\n",
    "    \n",
    "    import os\n",
    "    import sys\n",
    "    module_path = os.path.abspath(os.path.join('..'))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gd7dyzCGwCZo"
   },
   "source": [
    "## General Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EGfclJp_AyA7"
   },
   "outputs": [],
   "source": [
    "# Imports for this notebook\n",
    "\n",
    "from models.nvs_model import NovelViewSynthesisModel\n",
    "from models.synthesis.synt_loss_metric import SynthesisLoss\n",
    "from util.nvs_solver import NVS_Solver\n",
    "from util.gan_wrapper_solver import GAN_Wrapper_Solver\n",
    "from data.nuim_dataloader import ICLNUIMDataset\n",
    "\n",
    "from torch.utils import data\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision.transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B7R9GHGlhsMQ"
   },
   "outputs": [],
   "source": [
    "# Check training on GPU?\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "print(\"Training is on GPU with CUDA: {}\".format(cuda))\n",
    "\n",
    "device = \"cuda:0\" if cuda else \"cpu\"\n",
    "\n",
    "print(\"Device: {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"Given a model return total number of parameters\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qKgCXiSPZgY1"
   },
   "source": [
    "# Model & Loss Init\n",
    "\n",
    "Instantiate and initialize NovelViewSynthesisModel and a selected flavor of SynthesisLoss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hzBJYgAlZgY2"
   },
   "outputs": [],
   "source": [
    "# TODO: Define more parameters in the dict according to availalbe ones in the model, as soon as they are needed.\n",
    "# Right now we just use the default parameters for the rest (see outcommented list or the .py file)\n",
    "    \n",
    "model_args={\n",
    "    'imageSize': 64,\n",
    "    \n",
    "    'use_gt_depth': True,\n",
    "    'normalize_images': False,\n",
    "    'use_rgb_features': False,\n",
    "    \n",
    "    'enc_dims': [3, 8, 8, 16, 16, 32, 32, 64, 64],\n",
    "    'enc_blk_types': [\"id\", \"id\", \"id\", \"id\", \"id\", \"id\", \"id\", \"id\"],\n",
    "    #'enc_dims': [3, 8, 8, 16, 16, 32, 32, 64, 64, 64],\n",
    "    #'enc_blk_types': [\"id\", \"id\", \"id\", \"id\", \"id\", \"id\", \"id\", \"id\", \"id\"],\n",
    "    #'enc_dims': [3, 8, 8],\n",
    "    #'enc_blk_types': [\"id\", \"id\"],\n",
    "    'enc_noisy_bn': False,\n",
    "    'enc_spectral_norm': False,\n",
    "    \n",
    "    'dec_activation_func': nn.Sigmoid(),\n",
    "    #'dec_dims': [64, 64, 32, 32, 32, 16, 16, 8, 8, 3],\n",
    "    #'dec_blk_types': [\"id\", \"id\", \"id\", \"id\", \"id\", \"id\", \"id\", \"id\", \"id\"],\n",
    "    'dec_dims': [64, 64, 32, 32, 16, 16, 8, 8, 3],\n",
    "    'dec_blk_types': [\"id\", \"id\", \"id\", \"id\", \"id\", \"id\", \"id\", \"id\"],\n",
    "    #'dec_dims': [3, 8, 8, 16, 16, 32, 32, 64, 64, 32, 32, 16, 16, 8, 8, 3],\n",
    "    #'dec_blk_types': [\"id\", \"id\", \"id\", \"id\", \"id\", \"id\", \"id\", \"id\", \"id\", \"id\", \"id\", \"id\", \"id\", \"id\", \"id\"],\n",
    "    'dec_noisy_bn': False,\n",
    "    'dec_spectral_norm': False,\n",
    "    \n",
    "    # from here attributes for the loss of the nvs_model\n",
    "    'l1_loss': '1.0_l1',\n",
    "    'content_loss': '1.0_content', # synsin default: 10.0\n",
    "}\n",
    "\n",
    "# keep this loss object constant and modify usage of losses by e.g. setting one coefficient to 0\n",
    "nvs_loss = SynthesisLoss(losses=[\n",
    "    model_args['l1_loss'],\n",
    "    model_args['content_loss']\n",
    "])\n",
    "\n",
    "model = NovelViewSynthesisModel(imageSize=model_args['imageSize'],\n",
    "                                \n",
    "                                #max_z=0,\n",
    "                                #min_z=0,\n",
    "                                \n",
    "                                enc_dims=model_args['enc_dims'],\n",
    "                                enc_blk_types=model_args['enc_blk_types'],\n",
    "                                enc_noisy_bn=model_args['enc_noisy_bn'],\n",
    "                                enc_spectral_norm=model_args['enc_spectral_norm'],\n",
    "                                \n",
    "                                dec_dims=model_args['dec_dims'],\n",
    "                                dec_blk_types=model_args['dec_blk_types'],\n",
    "                                dec_activation_func=model_args['dec_activation_func'],\n",
    "                                dec_noisy_bn=model_args['dec_noisy_bn'],\n",
    "                                dec_spectral_norm=model_args['dec_spectral_norm'],\n",
    "                                \n",
    "                                #points_per_pixel=8,\n",
    "                                #learn_feature=True,\n",
    "                                #radius=1.5,\n",
    "                                #rad_pow=2,\n",
    "                                #accumulation='alphacomposite',\n",
    "                                #accumulation_tau=1,\n",
    "                                \n",
    "                                use_rgb_features=model_args['use_rgb_features'],\n",
    "                                use_gt_depth=model_args['use_gt_depth'],\n",
    "                                #use_inverse_depth=False,\n",
    "                                normalize_images=model_args['normalize_images'])\n",
    "model_args[\"model\"] = type(model).__name__\n",
    "\n",
    "print(\"Model configuration: {}\".format(model_args))\n",
    "\n",
    "print(\"Architecture:\", model)\n",
    "print(\"Total number of paramaters:\", count_parameters(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QkO15Cr3t3pA"
   },
   "source": [
    "# Load Data\n",
    "Load ICL-NUIM dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TcKlv4vsAyBE"
   },
   "outputs": [],
   "source": [
    "# Load dataset from drive or local\n",
    "\n",
    "if is_on_colab:\n",
    "    path = \"/content/drive/My Drive/Novel_View_Synthesis/ICL-NUIM/living_room_traj2_loop\"\n",
    "else:\n",
    "    path = \"/home/lukas/Desktop/datasets/ICL-NUIM/prerendered_data/living_room_traj2_loop\"\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    #torchvision.transforms.ToPILImage(), # no longer needed: new dataloader now returns PIL Images\n",
    "    torchvision.transforms.Resize((model_args['imageSize'], model_args['imageSize'])),\n",
    "    torchvision.transforms.ToTensor(), \n",
    "])\n",
    "    \n",
    "data_dict = {\n",
    "    \"path\": path,\n",
    "    \"depth_to_image_plane\": True,\n",
    "    \"use_real_intrinsics\": False,\n",
    "    \"sampleOutput\": True,\n",
    "    \"RTrelativeToOutput\": False,\n",
    "    \"inverse_depth\": False,\n",
    "    \"cacheItems\": True, # Caching will work only if num_workers = 0. Decide what you like more!\n",
    "}\n",
    "    \n",
    "dataset = ICLNUIMDataset(path,\n",
    "                         transform=transform,\n",
    "                         depth_to_image_plane=data_dict[\"depth_to_image_plane\"],\n",
    "                         use_real_intrinsics=data_dict[\"use_real_intrinsics\"],\n",
    "                         sampleOutput=data_dict[\"sampleOutput\"],\n",
    "                         RTrelativeToOutput=data_dict[\"RTrelativeToOutput\"],\n",
    "                         inverse_depth=data_dict[\"inverse_depth\"],\n",
    "                         cacheItems=data_dict[\"cacheItems\"])\n",
    "\n",
    "print(\"Loaded following data: {} (samples: {}) with configuration: {}\".format(data_dict[\"path\"], len(dataset), data_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aJLyrjl2AyBK"
   },
   "outputs": [],
   "source": [
    "# Create Train and Val dataset with 80% train and 20% val.\n",
    "# from: https://stackoverflow.com/questions/50544730/how-do-i-split-a-custom-dataset-into-training-and-test-datasets\n",
    "\n",
    "dataset_args = {\n",
    "    \"batch_size\": 8,\n",
    "    \"validation_percentage\": 0.2,\n",
    "    \"shuffle_dataset\": True,\n",
    "    **data_dict\n",
    "}\n",
    "\n",
    "num_workers = 0 # Dataset Caching will work only if num_workers = 0. Decide what you like more!\n",
    "random_seed = 42 # seed random generation for shuffeling indices to always get same images in train/val\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(dataset_args[\"validation_percentage\"] * dataset_size))\n",
    "if dataset_args[\"shuffle_dataset\"]:\n",
    "    #np.random.seed(random_seed) # DO NOT SEED\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# OVERFITTING CASE:\n",
    "train_indices = [train_indices[0]] # train_indices[0:4] # [train_indices[0]]\n",
    "val_indices = val_indices[:10]\n",
    "\n",
    "overfit_item = dataset.__getitem__(train_indices[0])\n",
    "print(\"OVERFITTING Input Image: {}, Output Image: {}\".format(\n",
    "    train_indices[0],\n",
    "    overfit_item[\"output\"][\"idx\"]))\n",
    "\n",
    "input_img = overfit_item[\"image\"].cpu().detach().numpy()\n",
    "output_img = overfit_item[\"output\"][\"image\"].cpu().detach().numpy()\n",
    "\n",
    "print(torch.min(overfit_item[\"output\"][\"image\"]))\n",
    "print(torch.max(overfit_item[\"output\"][\"image\"]))\n",
    "print(overfit_item[\"cam\"])\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"OVERFIT TRAIN INPUT IMAGE\")\n",
    "plt.imshow(np.moveaxis(input_img, 0, -1))\n",
    "plt.show()\n",
    "\n",
    "print(\"OVERFIT TRAIN OUTPUT IMAGE\")\n",
    "plt.imshow(np.moveaxis(output_img, 0, -1))\n",
    "plt.show()\n",
    "\n",
    "# END OVERFITTING CASE\n",
    "\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=dataset_args[\"batch_size\"], \n",
    "                                           sampler=train_sampler, num_workers=num_workers)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=dataset_args[\"batch_size\"],\n",
    "                                                sampler=valid_sampler, num_workers=num_workers)\n",
    "\n",
    "dataset_args[\"train_len\"] = len(train_loader)\n",
    "dataset_args[\"val_len\"] = len(validation_loader)\n",
    "\n",
    "print(\"Dataset parameters: {}\".format(dataset_args))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HeFz-j00u5LR"
   },
   "source": [
    "# Training Visualization\n",
    "\n",
    "Start Tensorboard for visualization of the upcoming training / validation / test steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c-6Mnrc-TPU9",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Start tensorboard. Might need to make sure, that the correct runs directory is chosen here.\n",
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir ../runs\n",
    "#!tensorboard --logdir ../runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-zet9gPxvM2i"
   },
   "source": [
    "# Training\n",
    "\n",
    "Start training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This flag decides with solver gets used and where the logs will be logged into (into which directory)\n",
    "train_with_discriminator = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OTnq2RYJy4Dn"
   },
   "outputs": [],
   "source": [
    "# Create unique ID for this training process for saving to disk.\n",
    "\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "now = datetime.now() # current date and time\n",
    "id = str(uuid.uuid1())\n",
    "id_suffix = now.strftime(\"%Y-%b-%d_%H-%M-%S\") + \"_\" + id\n",
    "\n",
    "if train_with_discriminator:\n",
    "    log_dir_name = \"Full_GAN\"\n",
    "else:\n",
    "    log_dir_name = \"Full_No_GAN\"\n",
    "\n",
    "log_dir = \"../runs/\" + log_dir_name + \"/\" + id_suffix # Might need to make sure, that the correct runs directory is chosen here.\n",
    "print(\"log_dir:\", log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QY38vRjuAyBc"
   },
   "outputs": [],
   "source": [
    "# Configure solver\n",
    "extra_args = {\n",
    "    **model_args,\n",
    "    **dataset_args\n",
    "}\n",
    "\n",
    "if train_with_discriminator:\n",
    "    solver = GAN_Wrapper_Solver(optim_d=torch.optim.Adam,\n",
    "                                optim_d_args={\"lr\": 1e-2,\n",
    "                                              \"betas\": (0.9, 0.999),\n",
    "                                              \"eps\": 1e-8,\n",
    "                                              \"weight_decay\": 0.0},# is the l2 regularization parameter, see: https://pytorch.org/docs/stable/optim.html\n",
    "                                optim_g=torch.optim.Adam,\n",
    "                                optim_g_args={\"lr\": 1e-4,\n",
    "                                              \"betas\": (0.9, 0.999),\n",
    "                                              \"eps\": 1e-8,\n",
    "                                              \"weight_decay\": 0.0}, # is the l2 regularization parameter, see: https://pytorch.org/docs/stable/optim.html\n",
    "                                g_loss_func=nvs_loss,\n",
    "                                extra_args=extra_args,\n",
    "                                log_dir=log_dir,\n",
    "                                init_discriminator_weights=True)\n",
    "else:\n",
    "    solver = NVS_Solver(optim=torch.optim.Adam,\n",
    "                        optim_args={\"lr\": 1,\n",
    "                                    \"betas\": (0.9, 0.999),\n",
    "                                    \"eps\": 1e-8,\n",
    "                                    \"weight_decay\": 0.0}, # is the l2 regularization parameter, see: https://pytorch.org/docs/stable/optim.html,\n",
    "                        loss_func=nvs_loss,\n",
    "                        extra_args=extra_args,\n",
    "                        tensorboard_writer=None, # let solver create a new instance\n",
    "                        log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1IhNe6ynzXox",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start training\n",
    "\n",
    "num_epochs=20\n",
    "log_nth_iter=10\n",
    "log_nth_epoch=1\n",
    "tqdm_mode='total'\n",
    "'''\n",
    "tqdm_mode:\n",
    "    'total': tqdm log how long all epochs will take,\n",
    "    'epoch': tqdm for each epoch how long it will take,\n",
    "    anything else, e.g. None: do not use tqdm\n",
    "'''\n",
    "\n",
    "# TODO: Add parameters to extra_args dict?\n",
    "if train_with_discriminator:\n",
    "    steps = 1 # how many steps of training for discriminator/generator before switching to generator/discriminator\n",
    "    solver.train(model,\n",
    "                 train_loader, \n",
    "                 validation_loader,\n",
    "                 num_epochs=num_epochs,\n",
    "                 log_nth_iter=log_nth_iter,\n",
    "                 log_nth_epoch=log_nth_epoch,\n",
    "                 tqdm_mode=tqdm_mode,\n",
    "                 steps=steps)\n",
    "else:\n",
    "    solver.train(model,\n",
    "                 train_loader,\n",
    "                 validation_loader,\n",
    "                 num_epochs=num_epochs,\n",
    "                 log_nth_iter=log_nth_iter,\n",
    "                 log_nth_epoch=log_nth_epoch,\n",
    "                 tqdm_mode=tqdm_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tVWNikT4PvGj"
   },
   "outputs": [],
   "source": [
    "# To download tensorboard runs from Colab\n",
    "\n",
    "# TODO: Make sure that only new ones are copied --> for tensorboard runs on colab, do not use git repository as \"runs\" directory?\n",
    "# TODO: Instead of downloading, directly move it to the git repository that is currently checked out and push changes?\n",
    "if is_on_colab:\n",
    "  from google.colab import files\n",
    "  !zip -r /content/runs.zip /content/runs\n",
    "  files.download(\"/content/runs.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P2VDewrSvags"
   },
   "source": [
    "# Test\n",
    "\n",
    "Test with test dataset.\n",
    "Will load the data and start the training.\n",
    "\n",
    "Visualizations can be seen in Tensorboard above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d8S9-1x0zbHZ"
   },
   "outputs": [],
   "source": [
    "# Load test data\n",
    "# TODO: Find real test split, for now we load the SAME dataset as for train/val (just that this notebook is complete...)\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "test_path = path # CHANGE HERE TO REAL PATH TO TEST SET\n",
    "\n",
    "test_dataset = dataset = ICLNUIMDataset(test_path, transform=transform) # TODO also use rest of parameters...\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=dataset_args[\"batch_size\"], \n",
    "                                               shuffle=True,\n",
    "                                               num_workers=4)\n",
    "\n",
    "print(\"Length of test set: {}\".format(len(test_dataset)))\n",
    "print(\"Loaded test set: {}\".format(test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cl2sFO4Kynp6"
   },
   "outputs": [],
   "source": [
    "# Start testing\n",
    "\n",
    "#solver.test(model, test_loader, test_prefix=\"DUMMY_TEST_WITH_NO_REAL_TEST_SET\", log_nth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pTLUJGpnBpud"
   },
   "source": [
    "# Save the model\n",
    "\n",
    "Save network with its weights to disk.\n",
    "\n",
    "See torch.save function: https://pytorch.org/docs/stable/notes/serialization.html#recommend-saving-models \n",
    "\n",
    "Load again with `the_model = TheModelClass(*args, **kwargs) the_model.load_state_dict(torch.load(PATH))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7_zjMVB7Bpue"
   },
   "outputs": [],
   "source": [
    "def save_model(modelname, model):\n",
    "    # Might need to make sure, that the correct saved_results directory is chosen here.\n",
    "    filepath = \"../saved_models/\" + modelname + \".pt\"\n",
    "    torch.save(model.state_dict(), filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2JfoL3IHBpuv"
   },
   "outputs": [],
   "source": [
    "nvs_modelname = \"nvs_\" + id_suffix\n",
    "save_model(nvs_modelname, model)\n",
    "\n",
    "if train_with_discriminator:\n",
    "    # Also save the discriminator - currently this can only be accessed through the solver (change it!)\n",
    "    gan_modelname = \"gan_\" + id_suffix\n",
    "    save_model(gan_modelname, solver.netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BwbC3OFOEmLX"
   },
   "outputs": [],
   "source": [
    "# LOAD MODEL AGAIN for verification purposes\n",
    "# Should print: <All keys matched successfully> per each model if it works\n",
    "\n",
    "nvs_filepath = \"../saved_models/\" + nvs_modelname + \".pt\"\n",
    "print(\"NVS_Model loading: \", model.load_state_dict(torch.load(nvs_filepath)))\n",
    "\n",
    "if train_with_discriminator:\n",
    "    gan_filepath = \"../saved_models/\" + gan_modelname + \".pt\"\n",
    "    print(\"Discriminator loading: \", solver.netD.load_state_dict(torch.load(gan_filepath)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "entire_network_notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "nvs",
   "language": "python",
   "name": "nvs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
