{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T21:19:46.234036Z",
     "start_time": "2020-08-07T21:19:46.230005Z"
    }
   },
   "outputs": [],
   "source": [
    "import habitat_sim\n",
    "import random\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import quaternion\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T21:19:46.786565Z",
     "start_time": "2020-08-07T21:19:46.783084Z"
    }
   },
   "outputs": [],
   "source": [
    "# path_to_mp3d = \"path/to/habitat-api/data/scene_datasets/mp3d/\"\n",
    "# folder_content = os.listdir(path_to_mp3d)\n",
    "# scene_paths = []\n",
    "# for content in folder_content:\n",
    "#     full_path = path_to_mp3d + content\n",
    "#     if os.path.isdir(full_path):\n",
    "#         full_path = full_path + \"/\" + content + \".glb\"\n",
    "#         # print(full_path)\n",
    "#         scene_paths.append(full_path)\n",
    "        \n",
    "# print(\"Total number of scenes:\", len(scene_paths))\n",
    "# test_scene = scene_paths[1]\n",
    "# print(\"Scene to be used:\", test_scene)\n",
    "\n",
    "modified_scene = \"/home/cengerkin/Desktop/habitat-full/habitat-api/data/scene_datasets/mp3d/testing/new/exp/exp1_semantic.ply\"\n",
    "\n",
    "sim_settings = {\n",
    "    \"width\": 256,  # Spatial resolution of the observations    \n",
    "    \"height\": 256,\n",
    "    \"scene\": modified_scene,  # Scene path\n",
    "    \"default_agent\": 0,  \n",
    "    \"sensor_height\": 0,  # Height of sensors in meters\n",
    "    \"color_sensor\": True,  # RGB sensor\n",
    "    \"semantic_sensor\": True,  # Semantic sensor\n",
    "    \"depth_sensor\": True,  # Depth sensor\n",
    "    \"seed\": 1,\n",
    "}\n",
    "\n",
    "# orig_scene = \"/home/cengerkin/Desktop/habitat-full/habitat-api/data/scene_datasets/mp3d/testing/new/region0_orig_semantic.ply\"\n",
    "\n",
    "# sim_settings = {\n",
    "#     \"width\": 256,  # Spatial resolution of the observations    \n",
    "#     \"height\": 256,\n",
    "#     \"scene\": orig_scene,  # Scene path\n",
    "#     \"default_agent\": 0,  \n",
    "#     \"sensor_height\": 0,  # Height of sensors in meters\n",
    "#     \"color_sensor\": True,  # RGB sensor\n",
    "#     \"semantic_sensor\": True,  # Semantic sensor\n",
    "#     \"depth_sensor\": True,  # Depth sensor\n",
    "#     \"seed\": 1,\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulator config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T20:46:10.251976Z",
     "start_time": "2020-08-07T20:46:09.395353Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0807 22:46:10.247082 16726 simulator.py:167] Could not find navmesh /home/cengerkin/Desktop/habitat-full/habitat-api/data/scene_datasets/mp3d/testing/new/exp/exp1_semantic.navmesh, no collision checking will be done\n"
     ]
    }
   ],
   "source": [
    "def make_cfg(settings):\n",
    "    sim_cfg = habitat_sim.SimulatorConfiguration()\n",
    "    sim_cfg.gpu_device_id = 0\n",
    "    sim_cfg.scene.id = settings[\"scene\"]\n",
    "    \n",
    "    # Note: all sensors must have the same resolution\n",
    "    sensors = {\n",
    "        \"color_sensor\": {\n",
    "            \"sensor_type\": habitat_sim.SensorType.COLOR,\n",
    "            \"resolution\": [settings[\"height\"], settings[\"width\"]],\n",
    "            \"position\": [0.0, settings[\"sensor_height\"], 0.0],\n",
    "        },\n",
    "        \"depth_sensor\": {\n",
    "            \"sensor_type\": habitat_sim.SensorType.DEPTH,\n",
    "            \"resolution\": [settings[\"height\"], settings[\"width\"]],\n",
    "            \"position\": [0.0, settings[\"sensor_height\"], 0.0],\n",
    "        },\n",
    "        \"semantic_sensor\": {\n",
    "            \"sensor_type\": habitat_sim.SensorType.SEMANTIC,\n",
    "            \"resolution\": [settings[\"height\"], settings[\"width\"]],\n",
    "            \"position\": [0.0, settings[\"sensor_height\"], 0.0],\n",
    "        },  \n",
    "    }\n",
    "    \n",
    "    sensor_specs = []\n",
    "    for sensor_uuid, sensor_params in sensors.items():\n",
    "        if settings[sensor_uuid]:\n",
    "            sensor_spec = habitat_sim.SensorSpec()\n",
    "            sensor_spec.uuid = sensor_uuid\n",
    "            sensor_spec.sensor_type = sensor_params[\"sensor_type\"]\n",
    "            sensor_spec.resolution = sensor_params[\"resolution\"]\n",
    "            sensor_spec.position = sensor_params[\"position\"]\n",
    "\n",
    "            sensor_specs.append(sensor_spec)\n",
    "            \n",
    "    # Here you can specify the amount of displacement in a forward action and the turn angle\n",
    "    agent_cfg = habitat_sim.agent.AgentConfiguration()\n",
    "    agent_cfg.sensor_specifications = sensor_specs\n",
    "    agent_cfg.action_space = {\n",
    "        \"move_forward\": habitat_sim.agent.ActionSpec(\n",
    "            \"move_forward\", habitat_sim.agent.ActuationSpec(amount=0.25)\n",
    "        ),\n",
    "        \"move_backward\": habitat_sim.agent.ActionSpec(\n",
    "            \"move_backward\", habitat_sim.agent.ActuationSpec(amount=0.25)\n",
    "        ),\n",
    "        \"move_right\": habitat_sim.agent.ActionSpec(\n",
    "            \"move_right\", habitat_sim.agent.ActuationSpec(amount=0.25)\n",
    "        ),\n",
    "        \"move_left\": habitat_sim.agent.ActionSpec(\n",
    "            \"move_left\", habitat_sim.agent.ActuationSpec(amount=0.25)\n",
    "        ),\n",
    "        \"turn_left\": habitat_sim.agent.ActionSpec(\n",
    "            \"turn_left\", habitat_sim.agent.ActuationSpec(amount=15.0)\n",
    "        ),\n",
    "        \"turn_right\": habitat_sim.agent.ActionSpec(\n",
    "            \"turn_right\", habitat_sim.agent.ActuationSpec(amount=15.0)\n",
    "        ),\n",
    "        \"look_up\": habitat_sim.agent.ActionSpec(\n",
    "            \"look_up\", habitat_sim.agent.ActuationSpec(amount=1)\n",
    "        ),\n",
    "        \"look_down\": habitat_sim.agent.ActionSpec(\n",
    "            \"look_down\", habitat_sim.agent.ActuationSpec(amount=1)\n",
    "        ),\n",
    "    }\n",
    "    \n",
    "    return habitat_sim.Configuration(sim_cfg, [agent_cfg])\n",
    "\n",
    "cfg = make_cfg(sim_settings)\n",
    "sim = habitat_sim.Simulator(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scene semantic annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T20:46:10.364798Z",
     "start_time": "2020-08-07T20:46:10.254103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House has 0 levels, 0 regions and 0 objects\n",
      "House center:[0. 0. 0.] dims:[-inf -inf -inf]\n"
     ]
    }
   ],
   "source": [
    "def print_scene_recur(scene, limit_output=10):\n",
    "    print(f\"House has {len(scene.levels)} levels, {len(scene.regions)} regions and {len(scene.objects)} objects\")\n",
    "    print(f\"House center:{scene.aabb.center} dims:{scene.aabb.sizes}\")\n",
    "    \n",
    "    count = 0\n",
    "    for level in scene.levels:\n",
    "        print(\n",
    "            f\"Level id:{level.id}, center:{level.aabb.center},\"\n",
    "            f\" dims:{level.aabb.sizes}\"\n",
    "        )\n",
    "        for region in level.regions:\n",
    "            print(\n",
    "                f\"Region id:{region.id}, category:{region.category.name()},\"\n",
    "                f\" center:{region.aabb.center}, dims:{region.aabb.sizes}\"\n",
    "            )\n",
    "            for obj in region.objects:\n",
    "                print(\n",
    "                    f\"Object id:{obj.id}, category:{obj.category.name()},\"\n",
    "                    f\" center:{obj.aabb.center}, dims:{obj.aabb.sizes}\"\n",
    "                )\n",
    "                count += 1\n",
    "                if count >= limit_output:\n",
    "                    return None\n",
    "\n",
    "# Print semantic annotation information (id, category, bounding box details) \n",
    "# about levels, regions and objects in a hierarchical fashion\n",
    "scene = sim.semantic_scene\n",
    "print_scene_recur(scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T20:46:10.450028Z",
     "start_time": "2020-08-07T20:46:10.367977Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_state: position [-2.6470983  4.6513968  6.468966 ] rotation quaternion(0.258819073438644, 0, -0.965925872325897, 0)\n"
     ]
    }
   ],
   "source": [
    "random.seed(sim_settings[\"seed\"])\n",
    "sim.seed(sim_settings[\"seed\"])\n",
    "\n",
    "# Set agent state\n",
    "agent = sim.initialize_agent(sim_settings[\"default_agent\"])\n",
    "agent_state = habitat_sim.AgentState()\n",
    "agent_state.position = np.array([-2.6470983, 4.6513968, 6.468966]) # TODO: Change here as desired\n",
    "agent_state.rotation = quaternion.quaternion(0.258819073438644, 0, -0.965925872325897, 0) # TODO: Change here as desired\n",
    "agent.set_state(agent_state)\n",
    "\n",
    "# Get agent state\n",
    "agent_state = agent.get_state()\n",
    "print(\"agent_state: position\", agent_state.position, \"rotation\", agent_state.rotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T21:19:53.226660Z",
     "start_time": "2020-08-07T21:19:53.207745Z"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from habitat_sim.utils.common import d3_40_colors_rgb\n",
    "\n",
    "def display_sample(rgb_obs, semantic_obs, depth_obs):\n",
    "    \"\"\"Plot RGB, Semantic and Depth images\"\"\"\n",
    "    rgb_img = Image.fromarray(rgb_obs, mode=\"RGB\")\n",
    "    \n",
    "    semantic_img = Image.new(\"P\", (semantic_obs.shape[1], semantic_obs.shape[0]))\n",
    "    semantic_img.putpalette(d3_40_colors_rgb.flatten())\n",
    "    semantic_img.putdata((semantic_obs.flatten() % 40).astype(np.uint8))\n",
    "    semantic_img = semantic_img.convert(\"RGB\")\n",
    "    \n",
    "    depth_img = Image.fromarray((depth_obs / 10 * 255).astype(np.uint8), mode=\"L\")\n",
    "\n",
    "    arr = [rgb_img, semantic_img, depth_img]\n",
    "    titles = ['rgb', 'semantic', 'depth']\n",
    "    plt.figure(figsize=(12 ,8))\n",
    "    for i, data in enumerate(arr):\n",
    "        ax = plt.subplot(1, 3, i+1)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(titles[i])\n",
    "        plt.imshow(data)\n",
    "    plt.show()\n",
    "    \n",
    "def get_camera_matrices(position, rotation):\n",
    "    rotation = quaternion.as_rotation_matrix(rotation)\n",
    "    \n",
    "    # Pinv: Agent/Camera pose wrt Habitat WCS\n",
    "    Pinv = np.eye(4)\n",
    "    Pinv[0:3, 0:3] = rotation\n",
    "    Pinv[0:3, 3] = position\n",
    "    # P: Habitat WCS wrt Agent/Camera\n",
    "    P = np.linalg.inv(Pinv)\n",
    "\n",
    "    return P, Pinv\n",
    "\n",
    "def get_visuals(observations):\n",
    "    \"\"\"Returns PIL versions of RGB, Semantic and Depth images, also returns Depth array\"\"\"\n",
    "    rgb_img = observations[\"color_sensor\"]\n",
    "    rgb_img = Image.fromarray(rgb_img, mode=\"RGB\")\n",
    "    \n",
    "    sem = observations[\"semantic_sensor\"]\n",
    "    sem_img = Image.new(\"P\", (sem.shape[1], sem.shape[0]))\n",
    "    sem_img.putpalette(d3_40_colors_rgb.flatten())\n",
    "    sem_img.putdata((sem.flatten() % 40).astype(np.uint8))\n",
    "    sem_img = sem_img.convert(\"RGB\")\n",
    "    \n",
    "    dep_arr = observations[\"depth_sensor\"]\n",
    "    dep_img = Image.fromarray((dep_arr / 10 * 255).astype(np.uint8), mode=\"L\")\n",
    "    \n",
    "    return rgb_img, sem_img, dep_img, dep_arr\n",
    "\n",
    "def collect_all_data(observations, state):\n",
    "    rgb_img, sem_img, _, dep_arr = get_visuals(observations)\n",
    "    P, Pinv = get_camera_matrices(state.position, state.rotation)\n",
    "    return rgb_img, sem_img, dep_arr, Pinv\n",
    "\n",
    "def split_RT(RT):\n",
    "    formatter={'float_kind':lambda x: \"%.10f\" % x}\n",
    "    R = RT[0:3, 0:3]\n",
    "    cam_pos = RT[0:3, 3].ravel()\n",
    "    cam_up = R[:, 1].ravel()  # y=cam_up (already unit)\n",
    "    cam_dir = R[:, 2].ravel() # z=cam_dir (already unit)\n",
    "    cam_pos = np.array2string(cam_pos, formatter=formatter, max_line_width=np.inf, separator=\", \")\n",
    "    cam_up = np.array2string(cam_up, formatter=formatter, max_line_width=np.inf, separator=\", \")\n",
    "    cam_dir = np.array2string(cam_dir, formatter=formatter, max_line_width=np.inf, separator=\", \")\n",
    "    return cam_pos, cam_up, cam_dir\n",
    "\n",
    "def save_data(path, index, rgb, sem, dep, Pinv):\n",
    "    file_name = \"sample_\" + str(index)\n",
    "    rgb.save(os.path.join(path, file_name + \".png\"))\n",
    "    sem.save(os.path.join(path, file_name + \".seg.png\"))\n",
    "    np.save(os.path.join(path, file_name + \".depth.npy\"), dep)\n",
    "    \n",
    "    cam_file_content = \"{:<12} = {}';\\n\"\n",
    "    cam_pos, cam_up, cam_dir = split_RT(Pinv)\n",
    "    info = cam_file_content.format(\"cam_pos\", cam_pos)\n",
    "    info += cam_file_content.format(\"cam_dir\", cam_dir)\n",
    "    info += cam_file_content.format(\"cam_up\", cam_up)\n",
    "    with open(os.path.join(path, file_name + \".txt\"), 'w+') as f:\n",
    "        f.write(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GUI with PyQt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T20:46:10.663958Z",
     "start_time": "2020-08-07T20:46:10.555921Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH1 = \"/home/cengerkin/Desktop/habitat-full/habitat-api/data/scene_datasets/mp3d/testing/new/exp/modified\"\n",
    "PATH2 = \"/home/cengerkin/Desktop/habitat-full/habitat-api/data/scene_datasets/mp3d/testing/new/exp\"\n",
    "PATH3 = \"/home/cengerkin/Desktop/habitat-full/habitat-api/data/scene_datasets/mp3d/testing/new/exp/orig\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T20:46:19.906042Z",
     "start_time": "2020-08-07T20:46:12.980802Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "from PyQt5.QtWidgets import *\n",
    "from PyQt5 import QtGui\n",
    "from PyQt5.QtGui import QPixmap\n",
    "from PyQt5.QtCore import Qt\n",
    "\n",
    "from PIL.ImageQt import ImageQt\n",
    "\n",
    "action_names = list(\n",
    "    cfg.agents[\n",
    "        sim_settings[\"default_agent\"]\n",
    "    ].action_space.keys()\n",
    ")\n",
    "\n",
    "action_map = {\n",
    "    Qt.Key_4: \"turn_left\",\n",
    "    Qt.Key_6: \"turn_right\",\n",
    "    Qt.Key_8: \"look_up\",\n",
    "    Qt.Key_5: \"look_down\",\n",
    "    Qt.Key_W: \"move_forward\",\n",
    "    Qt.Key_A: \"move_left\",\n",
    "    Qt.Key_S: \"move_backward\",\n",
    "    Qt.Key_D: \"move_right\"\n",
    "}\n",
    "\n",
    "state_hist = [] # Keep agent state when a sample is taken\n",
    "\n",
    "class MainWindow(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.initialize()\n",
    "        \n",
    "    def get_imageQt(self, observations):\n",
    "        \"\"\"Returns Qt versions of RGB, Semantic and Depth images\"\"\"\n",
    "        rgb_img, sem_img, dep_img, _ = get_visuals(observations)\n",
    "        rgb_img = ImageQt(rgb_img)\n",
    "        rgb_img = QPixmap.fromImage(rgb_img)\n",
    "        \n",
    "        sem_img = ImageQt(sem_img)\n",
    "        sem_img = QPixmap.fromImage(sem_img)\n",
    "        \n",
    "        dep_img = ImageQt(dep_img)\n",
    "        dep_img = QPixmap.fromImage(dep_img)\n",
    "        return rgb_img, sem_img, dep_img \n",
    "        \n",
    "    def initialize(self):\n",
    "        self.title = \"Habitat Agent\"\n",
    "        self.top = 0\n",
    "        self.left = 0\n",
    "        self.width = 256*3\n",
    "        self.height = 456\n",
    "        self.timestep = 0\n",
    "        \n",
    "        hbox = QHBoxLayout()\n",
    "        \n",
    "        rgb_panel = QFrame()\n",
    "        rgb_panel.setFrameShape(QFrame.StyledPanel)\n",
    "        self.rgb_panel = QLabel(rgb_panel)\n",
    "        \n",
    "        seg_panel = QFrame()\n",
    "        seg_panel.setFrameShape(QFrame.StyledPanel)\n",
    "        self.seg_panel = QLabel(seg_panel)\n",
    "        \n",
    "        dep_panel = QFrame()\n",
    "        dep_panel.setFrameShape(QFrame.StyledPanel)\n",
    "        self.dep_panel = QLabel(dep_panel)\n",
    "        \n",
    "        self.info_panel = info_panel = QPlainTextEdit()\n",
    "        info_panel.setReadOnly(True)\n",
    "\n",
    "        split1 = QSplitter(Qt.Horizontal)\n",
    "        split1.addWidget(rgb_panel)\n",
    "        split1.addWidget(seg_panel)\n",
    "        split1.setSizes([256,256])\n",
    "        \n",
    "        split2 = QSplitter(Qt.Horizontal)\n",
    "        split2.addWidget(split1)\n",
    "        split2.addWidget(dep_panel)\n",
    "        split2.setSizes([512,256])\n",
    "        \n",
    "        split3 = QSplitter(Qt.Vertical)\n",
    "        split3.addWidget(split2)\n",
    "        split3.addWidget(info_panel)\n",
    "        split3.setSizes([256,200])\n",
    "        hbox.addWidget(split3)\n",
    "        \n",
    "        # Render images on respective windows\n",
    "        observations = sim.get_sensor_observations()\n",
    "        agent_state = agent.get_state()\n",
    "        # P, Pinv = get_camera_matrices(agent_state.position, agent_state.rotation)\n",
    "        \n",
    "        rgb, seg, dep = self.get_imageQt(observations)\n",
    "        self.rgb_panel.setPixmap(rgb)\n",
    "        self.seg_panel.setPixmap(seg)\n",
    "        self.dep_panel.setPixmap(dep)\n",
    "\n",
    "        log = \"t: {}, Position: {}, Orientation: {}\".format(self.timestep, agent_state.position, agent_state.rotation)\n",
    "        self.info_panel.appendPlainText(log)\n",
    "        \n",
    "        self.setLayout(hbox)\n",
    "        self.setWindowTitle(self.title)\n",
    "        self.setGeometry(self.left, self.top, self.width, self.height)\n",
    "        \n",
    "        self.show()\n",
    "\n",
    "    def keyPressEvent(self, event):\n",
    "        key = event.key()\n",
    "        # Clear logger\n",
    "        if key == Qt.Key_C:\n",
    "            self.info_panel.clear()\n",
    "        \n",
    "        # Close window\n",
    "        elif key == Qt.Key_Escape:\n",
    "            self.close()\n",
    "        \n",
    "        # Save current observation\n",
    "        elif key == Qt.Key_P:\n",
    "            observations = sim.get_sensor_observations()\n",
    "            agent_state = agent.get_state()\n",
    "            file_index = len(state_hist)\n",
    "            state_hist.append(agent_state)\n",
    "            data = collect_all_data(observations, agent_state)\n",
    "            save_data(PATH1, file_index, *data)\n",
    "            log = \"Saving data at t:{}\".format(self.timestep)\n",
    "            self.info_panel.appendPlainText(log)\n",
    "            \n",
    "        # TODO: Adjustable speed\n",
    "        elif key == Qt.Key_Plus:\n",
    "            agent.agent_config.action_space[\"move_forward\"].actuation.amount += 0.1\n",
    "        elif key == Qt.Key_Minus:\n",
    "            agent.agent_config.action_space[\"move_forward\"].actuation.amount -= 0.1\n",
    "        \n",
    "        # Take an action\n",
    "        else:\n",
    "            action = action_map[key]\n",
    "            observations = sim.step(action)\n",
    "            self.timestep += 1\n",
    "            \n",
    "            agent_state = agent.get_state()\n",
    "            # P, Pinv = get_camera_matrices(agent_state.position, agent_state.rotation)\n",
    "            \n",
    "            rgb, seg, dep = self.get_imageQt(observations)\n",
    "            self.rgb_panel.setPixmap(rgb)\n",
    "            self.seg_panel.setPixmap(seg)\n",
    "            self.dep_panel.setPixmap(dep)\n",
    "            \n",
    "            log = \"t:{}, Position: {}, Orientation: {}\".format(self.timestep, agent_state.position, agent_state.rotation)\n",
    "            self.info_panel.appendPlainText(log)\n",
    "\n",
    "\n",
    "\n",
    "app = QApplication([])\n",
    "\n",
    "window = MainWindow()\n",
    "\n",
    "window.show()\n",
    "app.exec_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T21:54:21.100429Z",
     "start_time": "2020-08-07T21:54:20.475955Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[227 119 194]\n"
     ]
    }
   ],
   "source": [
    "# Identify segmentation color for the modified object\n",
    "OBJID = 12\n",
    "color = d3_40_colors_rgb[OBJID]\n",
    "print(color)\n",
    "color = np.broadcast_to(color, (256, 256, 3))\n",
    "img = Image.fromarray(color, mode=\"RGB\")\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample from the Same Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T20:37:10.760390Z",
     "start_time": "2020-08-07T20:37:10.754707Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save trajectory\n",
    "line = \"Position: {}, Orientation: {}\\n\"\n",
    "\n",
    "with open(os.path.join(PATH2, \"trajectory.txt\"), \"w+\") as file:\n",
    "    for state in state_hist:\n",
    "        newline = line.format(state.position, state.rotation)\n",
    "        file.write(newline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-07T20:37:13.443Z"
    }
   },
   "outputs": [],
   "source": [
    "# Open unmodified scene and sample images from the same sequence.\n",
    "\n",
    "agent_state = agent.get_state()\n",
    "\n",
    "for time, state in enumerate(state_hist):\n",
    "    agent_state.position = state.position\n",
    "    agent_state.rotation = state.rotation\n",
    "    observations = sim.get_sensor_observations()\n",
    "    data = collect_all_data(observations, agent_state)\n",
    "    save_data(PATH3, time, *data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Take Specified Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T21:24:05.122267Z",
     "start_time": "2020-08-06T21:24:04.846692Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "action_names = list(\n",
    "    cfg.agents[\n",
    "        sim_settings[\"default_agent\"]\n",
    "    ].action_space.keys()\n",
    ")\n",
    "\n",
    "action_map = {\n",
    "    49: \"turn_left\",\n",
    "    50: \"turn_right\",\n",
    "    51: \"look_up\",\n",
    "    52: \"look_down\",\n",
    "    **dict.fromkeys((87, 119), \"move_forward\"),\n",
    "    **dict.fromkeys((65, 97), \"move_left\"),\n",
    "    **dict.fromkeys((83, 115), \"move_backward\"),\n",
    "    **dict.fromkeys((68, 100), \"move_right\")\n",
    "}\n",
    "\n",
    "run = True\n",
    "\n",
    "while run:\n",
    "    try:\n",
    "        button = ord(input(\"Press a key [W/A/S/D/1/2/3/4]: \"))\n",
    "        if button not in (69, 99):\n",
    "            #clear_output(): flush output\n",
    "            action = action_map[button]\n",
    "            print(\"Action\", action)\n",
    "            observations = sim.step(action)\n",
    "        else:\n",
    "            observations = sim.get_sensor_observations()\n",
    "        \n",
    "        rgb = observations[\"color_sensor\"]\n",
    "        semantic = observations[\"semantic_sensor\"]\n",
    "        depth = observations[\"depth_sensor\"]\n",
    "\n",
    "        display_sample(rgb, semantic, depth)\n",
    "        \n",
    "#         agent_state = agent.get_state()\n",
    "#         to_cam, to_habitat = get_camera_matrices(agent_state.position, agent_state.rotation)\n",
    "#         print(\"Agent state, Position:\", agent_state.position, \"Rotation:\", agent_state.rotation)\n",
    "#         print(\"From Habitat to Camera:\")\n",
    "#         print(to_cam)\n",
    "#         print(\"From Camera Matrix to Habitat:\")\n",
    "#         print(to_habitat)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        run = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Take Random Actions and Display Sensor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T21:24:05.127929Z",
     "start_time": "2020-08-06T21:24:04.739Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "total_frames = 0\n",
    "action_names = list(\n",
    "    cfg.agents[\n",
    "        sim_settings[\"default_agent\"]\n",
    "    ].action_space.keys()\n",
    ")\n",
    "\n",
    "print(action_names)\n",
    "\n",
    "max_frames = 5\n",
    "\n",
    "while total_frames < max_frames:\n",
    "    action = random.choice(action_names)\n",
    "    print(\"action\", action)\n",
    "    observations = sim.step(action)\n",
    "    rgb = observations[\"color_sensor\"]\n",
    "    semantic = observations[\"semantic_sensor\"]\n",
    "    depth = observations[\"depth_sensor\"]\n",
    "    \n",
    "    display_sample(rgb, semantic, depth)\n",
    "    \n",
    "    total_frames += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
