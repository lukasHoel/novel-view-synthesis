{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T21:35:36.664897Z",
     "start_time": "2020-08-06T21:35:35.366127Z"
    }
   },
   "outputs": [],
   "source": [
    "import habitat_sim\n",
    "import random\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import quaternion\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T21:35:36.671363Z",
     "start_time": "2020-08-06T21:35:36.667115Z"
    }
   },
   "outputs": [],
   "source": [
    "# path_to_mp3d = \"path/to/habitat-api/data/scene_datasets/mp3d/\"\n",
    "# folder_content = os.listdir(path_to_mp3d)\n",
    "# scene_paths = []\n",
    "# for content in folder_content:\n",
    "#     full_path = path_to_mp3d + content\n",
    "#     if os.path.isdir(full_path):\n",
    "#         full_path = full_path + \"/\" + content + \".glb\"\n",
    "#         # print(full_path)\n",
    "#         scene_paths.append(full_path)\n",
    "        \n",
    "# print(\"Total number of scenes:\", len(scene_paths))\n",
    "# test_scene = scene_paths[1]\n",
    "# print(\"Scene to be used:\", test_scene)\n",
    "\n",
    "test_scene = \"/home/cengerkin/Desktop/habitat-full/habitat-api/data/scene_datasets/mp3d/testing/new/exp/exp1_semantic.ply\"\n",
    "\n",
    "sim_settings = {\n",
    "    \"width\": 256,  # Spatial resolution of the observations    \n",
    "    \"height\": 256,\n",
    "    \"scene\": test_scene,  # Scene path\n",
    "    \"default_agent\": 0,  \n",
    "    \"sensor_height\": 0,  # Height of sensors in meters\n",
    "    \"color_sensor\": True,  # RGB sensor\n",
    "    \"semantic_sensor\": True,  # Semantic sensor\n",
    "    \"depth_sensor\": True,  # Depth sensor\n",
    "    \"seed\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulator config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T21:35:37.696774Z",
     "start_time": "2020-08-06T21:35:36.673045Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0806 23:35:37.690544 29661 simulator.py:167] Could not find navmesh /home/cengerkin/Desktop/habitat-full/habitat-api/data/scene_datasets/mp3d/testing/new/exp/exp1_semantic.navmesh, no collision checking will be done\n"
     ]
    }
   ],
   "source": [
    "def make_cfg(settings):\n",
    "    sim_cfg = habitat_sim.SimulatorConfiguration()\n",
    "    sim_cfg.gpu_device_id = 0\n",
    "    sim_cfg.scene.id = settings[\"scene\"]\n",
    "    \n",
    "    # Note: all sensors must have the same resolution\n",
    "    sensors = {\n",
    "        \"color_sensor\": {\n",
    "            \"sensor_type\": habitat_sim.SensorType.COLOR,\n",
    "            \"resolution\": [settings[\"height\"], settings[\"width\"]],\n",
    "            \"position\": [0.0, settings[\"sensor_height\"], 0.0],\n",
    "        },\n",
    "        \"depth_sensor\": {\n",
    "            \"sensor_type\": habitat_sim.SensorType.DEPTH,\n",
    "            \"resolution\": [settings[\"height\"], settings[\"width\"]],\n",
    "            \"position\": [0.0, settings[\"sensor_height\"], 0.0],\n",
    "        },\n",
    "        \"semantic_sensor\": {\n",
    "            \"sensor_type\": habitat_sim.SensorType.SEMANTIC,\n",
    "            \"resolution\": [settings[\"height\"], settings[\"width\"]],\n",
    "            \"position\": [0.0, settings[\"sensor_height\"], 0.0],\n",
    "        },  \n",
    "    }\n",
    "    \n",
    "    sensor_specs = []\n",
    "    for sensor_uuid, sensor_params in sensors.items():\n",
    "        if settings[sensor_uuid]:\n",
    "            sensor_spec = habitat_sim.SensorSpec()\n",
    "            sensor_spec.uuid = sensor_uuid\n",
    "            sensor_spec.sensor_type = sensor_params[\"sensor_type\"]\n",
    "            sensor_spec.resolution = sensor_params[\"resolution\"]\n",
    "            sensor_spec.position = sensor_params[\"position\"]\n",
    "\n",
    "            sensor_specs.append(sensor_spec)\n",
    "            \n",
    "    # Here you can specify the amount of displacement in a forward action and the turn angle\n",
    "    agent_cfg = habitat_sim.agent.AgentConfiguration()\n",
    "    agent_cfg.sensor_specifications = sensor_specs\n",
    "    agent_cfg.action_space = {\n",
    "        \"move_forward\": habitat_sim.agent.ActionSpec(\n",
    "            \"move_forward\", habitat_sim.agent.ActuationSpec(amount=0.25)\n",
    "        ),\n",
    "        \"move_backward\": habitat_sim.agent.ActionSpec(\n",
    "            \"move_backward\", habitat_sim.agent.ActuationSpec(amount=0.25)\n",
    "        ),\n",
    "        \"move_right\": habitat_sim.agent.ActionSpec(\n",
    "            \"move_right\", habitat_sim.agent.ActuationSpec(amount=0.25)\n",
    "        ),\n",
    "        \"move_left\": habitat_sim.agent.ActionSpec(\n",
    "            \"move_left\", habitat_sim.agent.ActuationSpec(amount=0.25)\n",
    "        ),\n",
    "        \"turn_left\": habitat_sim.agent.ActionSpec(\n",
    "            \"turn_left\", habitat_sim.agent.ActuationSpec(amount=15.0)\n",
    "        ),\n",
    "        \"turn_right\": habitat_sim.agent.ActionSpec(\n",
    "            \"turn_right\", habitat_sim.agent.ActuationSpec(amount=15.0)\n",
    "        ),\n",
    "        \"look_up\": habitat_sim.agent.ActionSpec(\n",
    "            \"look_up\", habitat_sim.agent.ActuationSpec(amount=1)\n",
    "        ),\n",
    "        \"look_down\": habitat_sim.agent.ActionSpec(\n",
    "            \"look_down\", habitat_sim.agent.ActuationSpec(amount=1)\n",
    "        ),\n",
    "    }\n",
    "    \n",
    "    return habitat_sim.Configuration(sim_cfg, [agent_cfg])\n",
    "\n",
    "cfg = make_cfg(sim_settings)\n",
    "sim = habitat_sim.Simulator(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scene semantic annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T21:35:37.888500Z",
     "start_time": "2020-08-06T21:35:37.698336Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House has 0 levels, 0 regions and 0 objects\n",
      "House center:[0. 0. 0.] dims:[-inf -inf -inf]\n"
     ]
    }
   ],
   "source": [
    "def print_scene_recur(scene, limit_output=10):\n",
    "    print(f\"House has {len(scene.levels)} levels, {len(scene.regions)} regions and {len(scene.objects)} objects\")\n",
    "    print(f\"House center:{scene.aabb.center} dims:{scene.aabb.sizes}\")\n",
    "    \n",
    "    count = 0\n",
    "    for level in scene.levels:\n",
    "        print(\n",
    "            f\"Level id:{level.id}, center:{level.aabb.center},\"\n",
    "            f\" dims:{level.aabb.sizes}\"\n",
    "        )\n",
    "        for region in level.regions:\n",
    "            print(\n",
    "                f\"Region id:{region.id}, category:{region.category.name()},\"\n",
    "                f\" center:{region.aabb.center}, dims:{region.aabb.sizes}\"\n",
    "            )\n",
    "            for obj in region.objects:\n",
    "                print(\n",
    "                    f\"Object id:{obj.id}, category:{obj.category.name()},\"\n",
    "                    f\" center:{obj.aabb.center}, dims:{obj.aabb.sizes}\"\n",
    "                )\n",
    "                count += 1\n",
    "                if count >= limit_output:\n",
    "                    return None\n",
    "\n",
    "# Print semantic annotation information (id, category, bounding box details) \n",
    "# about levels, regions and objects in a hierarchical fashion\n",
    "scene = sim.semantic_scene\n",
    "print_scene_recur(scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T21:35:38.001529Z",
     "start_time": "2020-08-06T21:35:37.892134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_state: position [-1.3634586  4.6513968  7.744606 ] rotation quaternion(1, 0, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "random.seed(sim_settings[\"seed\"])\n",
    "sim.seed(sim_settings[\"seed\"])\n",
    "\n",
    "# Set agent state\n",
    "agent = sim.initialize_agent(sim_settings[\"default_agent\"])\n",
    "agent_state = habitat_sim.AgentState()\n",
    "agent_state.position = np.array([-1.3634586334228516, 4.651396751403809, 7.744606018066406]) # TODO: Change here as desired\n",
    "# agent_state.rotation = quaternion.quaternion(1, 0, 0, 0) # TODO: Change here as desired\n",
    "agent.set_state(agent_state)\n",
    "\n",
    "# Get agent state\n",
    "agent_state = agent.get_state()\n",
    "print(\"agent_state: position\", agent_state.position, \"rotation\", agent_state.rotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T21:35:43.426694Z",
     "start_time": "2020-08-06T21:35:43.418345Z"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from habitat_sim.utils.common import d3_40_colors_rgb\n",
    "\n",
    "def display_sample(rgb_obs, semantic_obs, depth_obs):\n",
    "    \"\"\"Plot RGB, Semantic and Depth images\"\"\"\n",
    "    rgb_img = Image.fromarray(rgb_obs, mode=\"RGBA\")\n",
    "    \n",
    "    semantic_img = Image.new(\"P\", (semantic_obs.shape[1], semantic_obs.shape[0]))\n",
    "    semantic_img.putpalette(d3_40_colors_rgb.flatten())\n",
    "    semantic_img.putdata((semantic_obs.flatten() % 40).astype(np.uint8))\n",
    "    semantic_img = semantic_img.convert(\"RGBA\")\n",
    "    \n",
    "    depth_img = Image.fromarray((depth_obs / 10 * 255).astype(np.uint8), mode=\"L\")\n",
    "\n",
    "    arr = [rgb_img, semantic_img, depth_img]\n",
    "    titles = ['rgb', 'semantic', 'depth']\n",
    "    plt.figure(figsize=(12 ,8))\n",
    "    for i, data in enumerate(arr):\n",
    "        ax = plt.subplot(1, 3, i+1)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(titles[i])\n",
    "        plt.imshow(data)\n",
    "    plt.show()\n",
    "    \n",
    "def get_camera_matrices(position, rotation):\n",
    "    rotation = quaternion.as_rotation_matrix(rotation)\n",
    "    \n",
    "    # Pinv: Agent/Camera pose wrt Habitat WCS\n",
    "    Pinv = np.eye(4)\n",
    "    Pinv[0:3, 0:3] = rotation\n",
    "    Pinv[0:3, 3] = position\n",
    "    # P: Habitat WCS wrt Agent/Camera\n",
    "    P = np.linalg.inv(Pinv)\n",
    "\n",
    "    return P, Pinv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GUI with PyQt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T21:35:58.743209Z",
     "start_time": "2020-08-06T21:35:44.562108Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "from PyQt5.QtWidgets import *\n",
    "from PyQt5 import QtGui\n",
    "from PyQt5.QtGui import QPixmap\n",
    "from PyQt5.QtCore import Qt\n",
    "\n",
    "from PIL.ImageQt import ImageQt\n",
    "\n",
    "action_names = list(\n",
    "    cfg.agents[\n",
    "        sim_settings[\"default_agent\"]\n",
    "    ].action_space.keys()\n",
    ")\n",
    "\n",
    "action_map = {\n",
    "    Qt.Key_4: \"turn_left\",\n",
    "    Qt.Key_6: \"turn_right\",\n",
    "    Qt.Key_8: \"look_up\",\n",
    "    Qt.Key_5: \"look_down\",\n",
    "    Qt.Key_W: \"move_forward\",\n",
    "    Qt.Key_A: \"move_left\",\n",
    "    Qt.Key_S: \"move_backward\",\n",
    "    Qt.Key_D: \"move_right\"\n",
    "}\n",
    "\n",
    "class MainWindow(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.initialize()\n",
    "        \n",
    "    def get_images(self, observations):\n",
    "        rgb_img = observations[\"color_sensor\"]\n",
    "        rgb_img = Image.fromarray(rgb_img, mode=\"RGBA\")\n",
    "        rgb_img = ImageQt(rgb_img)\n",
    "        rgb_img = QPixmap.fromImage(rgb_img)\n",
    "        \n",
    "        sem = observations[\"semantic_sensor\"]\n",
    "        sem_img = Image.new(\"P\", (sem.shape[1], sem.shape[0]))\n",
    "        sem_img.putpalette(d3_40_colors_rgb.flatten())\n",
    "        sem_img.putdata((sem.flatten() % 40).astype(np.uint8))\n",
    "        sem_img = sem_img.convert(\"RGBA\")\n",
    "        sem_img = ImageQt(sem_img)\n",
    "        sem_img = QPixmap.fromImage(sem_img)\n",
    "        \n",
    "        dep_img = observations[\"depth_sensor\"]\n",
    "        dep_img = Image.fromarray((dep_img / 10 * 255).astype(np.uint8), mode=\"L\")\n",
    "        dep_img = ImageQt(dep_img)\n",
    "        dep_img = QPixmap.fromImage(dep_img)\n",
    "        return rgb_img, sem_img, dep_img \n",
    "        \n",
    "    def initialize(self):\n",
    "        self.title = \"Habitat Agent\"\n",
    "        self.top = 0\n",
    "        self.left = 0\n",
    "        self.width = 256*3\n",
    "        self.height = 456\n",
    "        self.timestep = 0\n",
    "        \n",
    "        hbox = QHBoxLayout()\n",
    "        \n",
    "        rgb_panel = QFrame()\n",
    "        rgb_panel.setFrameShape(QFrame.StyledPanel)\n",
    "        self.rgb_panel = QLabel(rgb_panel)\n",
    "        \n",
    "        seg_panel = QFrame()\n",
    "        seg_panel.setFrameShape(QFrame.StyledPanel)\n",
    "        self.seg_panel = QLabel(seg_panel)\n",
    "        \n",
    "        dep_panel = QFrame()\n",
    "        dep_panel.setFrameShape(QFrame.StyledPanel)\n",
    "        self.dep_panel = QLabel(dep_panel)\n",
    "        \n",
    "        self.info_panel = info_panel = QPlainTextEdit()\n",
    "        info_panel.setReadOnly(True)\n",
    "\n",
    "        split1 = QSplitter(Qt.Horizontal)\n",
    "        split1.addWidget(rgb_panel)\n",
    "        split1.addWidget(seg_panel)\n",
    "        split1.setSizes([256,256])\n",
    "        \n",
    "        split2 = QSplitter(Qt.Horizontal)\n",
    "        split2.addWidget(split1)\n",
    "        split2.addWidget(dep_panel)\n",
    "        split2.setSizes([512,256])\n",
    "        \n",
    "        split3 = QSplitter(Qt.Vertical)\n",
    "        split3.addWidget(split2)\n",
    "        split3.addWidget(info_panel)\n",
    "        split3.setSizes([256,200])\n",
    "        hbox.addWidget(split3)\n",
    "        \n",
    "        # Render images on respective windows\n",
    "        observations = sim.get_sensor_observations()\n",
    "        agent_state = agent.get_state()\n",
    "        \n",
    "        rgb, seg, dep = self.get_images(observations)\n",
    "        self.rgb_panel.setPixmap(rgb)\n",
    "        self.seg_panel.setPixmap(seg)\n",
    "        self.dep_panel.setPixmap(dep)\n",
    "        agent_state = agent.get_state()\n",
    "        log = \"t: {}, Position: {}, Orientation: {}\".format(self.timestep, agent_state.position, agent_state.rotation)\n",
    "        self.info_panel.appendPlainText(log)\n",
    "        \n",
    "        self.setLayout(hbox)\n",
    "        self.setWindowTitle(self.title)\n",
    "        self.setGeometry(self.left, self.top, self.width, self.height)\n",
    "        \n",
    "        self.show()\n",
    "\n",
    "    def keyPressEvent(self, event):\n",
    "        key = event.key()\n",
    "        if key == Qt.Key_C:\n",
    "            self.info_panel.clear()\n",
    "        elif key == Qt.Key_Escape:\n",
    "            self.close() \n",
    "        else:\n",
    "            action = action_map[key]\n",
    "            observations = sim.step(action)\n",
    "            self.timestep += 1\n",
    "            \n",
    "            rgb, seg, dep = self.get_images(observations)\n",
    "            self.rgb_panel.setPixmap(rgb)\n",
    "            self.seg_panel.setPixmap(seg)\n",
    "            self.dep_panel.setPixmap(dep)\n",
    "            agent_state = agent.get_state()\n",
    "            log = \"t:{}, Position: {}, Orientation: {}\".format(self.timestep, agent_state.position, agent_state.rotation)\n",
    "            self.info_panel.appendPlainText(log)\n",
    "\n",
    "#             agent_state = agent.get_state()\n",
    "#             to_cam, to_habitat = get_camera_matrices(agent_state.position, agent_state.rotation)\n",
    "#             print(\"Agent state, Position:\", agent_state.position, \"Rotation:\", agent_state.rotation)\n",
    "#             print(\"From Habitat to Camera:\")\n",
    "#             print(to_cam)\n",
    "#             print(\"From Camera Matrix to Habitat:\")\n",
    "#             print(to_habitat)\n",
    "\n",
    "\n",
    "app = QApplication([])\n",
    "\n",
    "window = MainWindow()\n",
    "\n",
    "window.show()\n",
    "app.exec_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Take Specified Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T21:24:05.122267Z",
     "start_time": "2020-08-06T21:24:04.846692Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "action_names = list(\n",
    "    cfg.agents[\n",
    "        sim_settings[\"default_agent\"]\n",
    "    ].action_space.keys()\n",
    ")\n",
    "\n",
    "action_map = {\n",
    "    49: \"turn_left\",\n",
    "    50: \"turn_right\",\n",
    "    51: \"look_up\",\n",
    "    52: \"look_down\",\n",
    "    **dict.fromkeys((87, 119), \"move_forward\"),\n",
    "    **dict.fromkeys((65, 97), \"move_left\"),\n",
    "    **dict.fromkeys((83, 115), \"move_backward\"),\n",
    "    **dict.fromkeys((68, 100), \"move_right\")\n",
    "}\n",
    "\n",
    "run = True\n",
    "\n",
    "while run:\n",
    "    try:\n",
    "        button = ord(input(\"Press a key [W/A/S/D/1/2/3/4]: \"))\n",
    "        if button not in (69, 99):\n",
    "            #clear_output(): flush output\n",
    "            action = action_map[button]\n",
    "            print(\"Action\", action)\n",
    "            observations = sim.step(action)\n",
    "        else:\n",
    "            observations = sim.get_sensor_observations()\n",
    "        \n",
    "        rgb = observations[\"color_sensor\"]\n",
    "        semantic = observations[\"semantic_sensor\"]\n",
    "        depth = observations[\"depth_sensor\"]\n",
    "\n",
    "        display_sample(rgb, semantic, depth)\n",
    "        \n",
    "#         agent_state = agent.get_state()\n",
    "#         to_cam, to_habitat = get_camera_matrices(agent_state.position, agent_state.rotation)\n",
    "#         print(\"Agent state, Position:\", agent_state.position, \"Rotation:\", agent_state.rotation)\n",
    "#         print(\"From Habitat to Camera:\")\n",
    "#         print(to_cam)\n",
    "#         print(\"From Camera Matrix to Habitat:\")\n",
    "#         print(to_habitat)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        run = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Take Random Actions and Display Sensor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T21:24:05.127929Z",
     "start_time": "2020-08-06T21:24:04.739Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "total_frames = 0\n",
    "action_names = list(\n",
    "    cfg.agents[\n",
    "        sim_settings[\"default_agent\"]\n",
    "    ].action_space.keys()\n",
    ")\n",
    "\n",
    "print(action_names)\n",
    "\n",
    "max_frames = 5\n",
    "\n",
    "while total_frames < max_frames:\n",
    "    action = random.choice(action_names)\n",
    "    print(\"action\", action)\n",
    "    observations = sim.step(action)\n",
    "    rgb = observations[\"color_sensor\"]\n",
    "    semantic = observations[\"semantic_sensor\"]\n",
    "    depth = observations[\"depth_sensor\"]\n",
    "    \n",
    "    display_sample(rgb, semantic, depth)\n",
    "    \n",
    "    total_frames += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
